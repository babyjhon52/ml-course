{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## day11: Text classification with simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "The text classification task is to determine its class from the document.\n",
    "\n",
    "In this case, it is proposed to consider as documents - letters pre-classified by 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories = fetch_20newsgroups().target_names\n",
    "all_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take only 3 topics, but from one section (documents from similar topics are more difficult to distinguish from each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'sci.electronics',\n",
    "    'sci.med',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train',\n",
    "                                categories=categories,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test',\n",
    "                               categories=categories,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text vectorization\n",
    "** Question: how to describe text documents with a feature space? **\n",
    "\n",
    "\n",
    "** Idea # 1 **: bag-of-words - each document or text looks like an unordered collection of words with no information about the relationships between them.\n",
    "<img src='https://st2.depositphotos.com/2454953/9959/i/450/depositphotos_99593622-stock-photo-holidays-travel-bag-word-cloud.jpg'>\n",
    "\n",
    "** Idea number 2 **: create a vector of \"words\", each component corresponds to a separate word.\n",
    "\n",
    "For text vectorization let's use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). You can vary the extraction of features in every possible way (remove rare words, remove frequent words, remove words of general vocabulary, take bigrams, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=5, ngram_range=(1, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_matrix = count_vectorizer.fit_transform(train_data.data)\n",
    "sparse_feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_2_words = {\n",
    "    v: k\n",
    "    for k, v in count_vectorizer.vocabulary_.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words with the highest positive weight are characteristic words of the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `macro`-average to estimate the quality of the solution in the multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer = make_scorer(f1_score, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Logistic Regression to Predict Document Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_algo_params = {\"solver\": \"liblinear\"}\n",
    "grid_search_params = {\n",
    "    \"verbose\": 1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"cv\": StratifiedKFold(shuffle=True, random_state=random_state),\n",
    "    \"scoring\": f_scorer,\n",
    "}\n",
    "\n",
    "lr_param_grid = {\n",
    "    \"C\": np.logspace(-4, 4, 9)\n",
    "}\n",
    "\n",
    "algo = LogisticRegression(**lr_algo_params)\n",
    "\n",
    "gscv_lr = GridSearchCV(algo, param_grid=lr_param_grid, **grid_search_params)\n",
    "gscv_lr.fit(sparse_feature_matrix, train_data.target)\n",
    "algo = gscv_lr.best_estimator_\n",
    "print(f\"best params: {gscv_lr.best_params_}\")\n",
    "train_accuracy = algo.score(sparse_feature_matrix, train_data.target)\n",
    "print(f\"train accuracy: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = algo.coef_.shape[1]\n",
    "\n",
    "for c in algo.classes_:\n",
    "    topic_words = [\n",
    "        num_2_words[w_num]\n",
    "        for w_num in heapq.nlargest(10, range(W), key=lambda w: algo.coef_[c, w])\n",
    "    ]\n",
    "    print(f\"topic: {categories[c]}\")\n",
    "    print(',  '.join(topic_words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the quality for train and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f_scorer(algo, sparse_feature_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer(algo, count_vectorizer.transform(test_data.data), test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The f-measure values are very low.\n",
    "\n",
    "** Question: ** what is the reason?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(algo.coef_[0], bins=500)\n",
    "plt.xlim([-0.06, 0.06])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Which metric to choose for regularization? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add L1 regularization to the logistic Regression\n",
    "algo = LogisticRegression(penalty=\"l1\", **lr_algo_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = cross_val_score(algo, sparse_feature_matrix, train_data.target, cv=grid_search_params[\"cv\"], scoring=f_scorer)\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.fit(sparse_feature_matrix, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_scorer(algo, sparse_feature_matrix, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer(algo, count_vectorizer.transform(test_data.data), test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the optimal value of the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plot(x, y, x_label, title, y_label='f_measure'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.grid(True),\n",
    "    plt.plot(x, y, 'go-')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.logspace(-2, 2, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = {\n",
    "    'C': np.logspace(-2, 2, 11),\n",
    "}\n",
    "gs = GridSearchCV(algo, lr_grid, **grid_search_params)\n",
    "%time  gs.fit(sparse_feature_matrix, train_data.target)\n",
    "print(f\"best_params: {gs.best_params_}, best_score: {gs.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим график:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plot(\n",
    "    np.log(lr_grid['C']), gs.cv_results_['mean_test_score'], 'C - coefficient of regularization', 'LogReg(penalty=l1)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_grid = {\n",
    "    \"C\": np.logspace(0, 2, 11), # OR YOUR CODE: create your own grid\n",
    "}\n",
    "gs = GridSearchCV(\n",
    "    LogisticRegression(**lr_algo_params),\n",
    "    lr_grid,\n",
    "    **grid_search_params\n",
    ")\n",
    "gs.fit(sparse_feature_matrix, train_data.target)\n",
    "print(f\"best_params: {gs.best_params_}, best_score: {gs.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_plot(\n",
    "    np.log(lr_grid['C']), gs.cv_results_['mean_test_score'], 'C - coefficient of regularization', 'LogReg(penalty=l1)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_final = LogisticRegression(penalty='l2', C=6.309573444801933, solver=\"liblinear\")\n",
    "%time lr_final.fit(sparse_feature_matrix, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(lr_final.predict(sparse_feature_matrix), train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_scorer(lr_final, sparse_feature_matrix, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(lr_final.predict(count_vectorizer.transform(test_data.data)), test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer(lr_final, count_vectorizer.transform(test_data.data), test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization along with feature vectorization\n",
    "In order not to do vectorization and training separately, there is a convenient Pipeline class. It allows you to chain a sequence of actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(min_df=5, ngram_range=(1, 2))),\n",
    "    (\"algo\", LogisticRegression(**lr_algo_params))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_data.data, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_scorer(pipeline, train_data.data, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer(pipeline, test_data.data, test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are the same as we got earlier, taking the steps separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation requires that the CountVectorizer does not learn on the test (otherwise the objects become dependent). Pipeline makes this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    CountVectorizer(min_df=5, ngram_range=(1, 2)),\n",
    "    LogisticRegression(penalty=\"l2\", **lr_algo_params)\n",
    ")\n",
    "arr = cross_val_score(pipeline, train_data.data, train_data.target, cv=5, scoring=f_scorer)\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New data preprocessing steps can be added to Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    CountVectorizer(min_df=5, ngram_range=(1, 2)),\n",
    "    TfidfTransformer(),\n",
    "    LogisticRegression(penalty=\"l2\", solver=\"liblinear\"),\n",
    ")\n",
    "arr = cross_val_score(pipeline, train_data.data, train_data.target, cv=5, scoring=f_scorer)\n",
    "print(arr)\n",
    "print(np.mean(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(train_data.data, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(pipeline.predict(train_data.data), train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_scorer(pipeline, train_data.data, train_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pipeline.predict(test_data.data), test_data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_scorer(pipeline, test_data.data, test_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality is slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: play with some other algorithm from sklearn than Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
