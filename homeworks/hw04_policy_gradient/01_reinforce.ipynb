{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVkCC1iri2SN"
      },
      "source": [
        "## HW 4: Policy gradient\n",
        "_Reference: based on Practical RL course by YSDA_\n",
        "\n",
        "In this notebook you have to master Policy gradient Q-learning and apply it to familiar (and not so familiar) RL problems once again.\n",
        "\n",
        "To get used to `gymnasium` package, please, refer to the [documentation](https://gymnasium.farama.org/introduction/basic_usage/).\n",
        "\n",
        "\n",
        "In the end of the notebook, please, copy the functions you have implemented to the template file and submit it to the Contest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "7UYczVTli2Sb"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "XPKYrIlai2Sf",
        "outputId": "3da453e8-0e63-4a88-b766-b1d703cc6898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78ca7949e2a0>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKBtJREFUeJzt3X9wVFWe9/FP5yc/uzMBkk4kQRQGiBCcAQy9Og4zZAgQHVnjljoMxFkeKNnEGojDYGYZFWfLuLi1/lqFemp3xa2SYWRKdGUEJgYJ6xgQM2T5JVlh2Q0udMLAphuiSUj6PH/4cMtWhHQSuk/C+1V1q9L3nO7+3lOp7k+de+5tlzHGCAAAwCJxsS4AAADgywgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6MQ0oL774oq6//noNGDBAeXl5+uCDD2JZDgAAsETMAspvfvMblZWV6bHHHtMf//hHTZ48WQUFBWpqaopVSQAAwBKuWP1YYF5enqZNm6Z/+Id/kCSFQiFlZWXpoYce0iOPPBKLkgAAgCUSYvGm7e3tqq2tVXl5ubMvLi5O+fn5qqmp+Ur/trY2tbW1OY9DoZDOnj2rYcOGyeVyRaVmAADQM8YYnTt3TpmZmYqLu/xJnJgElD/96U/q7OxUenp62P709HQdOXLkK/0rKiq0evXqaJUHAACuohMnTmjkyJGX7ROTgBKp8vJylZWVOY8DgYCys7N14sQJud3uGFYGAAC6KhgMKisrS0OHDr1i35gElOHDhys+Pl6NjY1h+xsbG+X1er/SPzk5WcnJyV/Z73a7CSgAAPQxXVmeEZOreJKSkjRlyhRVVVU5+0KhkKqqquTz+WJREgAAsEjMTvGUlZWpuLhYU6dO1S233KJnn31WLS0t+slPfhKrkgAAgCViFlDuvfdenT59Wo8++qj8fr9uvvlmbdu27SsLZwEAwLUnZvdB6YlgMCiPx6NAIMAaFAAA+ohIvr/5LR4AAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOv0ekB5/PHH5XK5wrbx48c77a2trSopKdGwYcM0ZMgQFRUVqbGxsbfLAAAAfdhVmUG56aabdOrUKWd77733nLbly5frrbfe0qZNm1RdXa2TJ0/q7rvvvhplAACAPirhqrxoQoK8Xu9X9gcCAf3TP/2TNmzYoO9///uSpJdfflkTJkzQ7t27NX369KtRDgAA6GOuygzKxx9/rMzMTN1www2aP3++GhoaJEm1tbW6cOGC8vPznb7jx49Xdna2ampqvvb12traFAwGwzYAANB/9XpAycvL0/r167Vt2zatXbtWx48f13e+8x2dO3dOfr9fSUlJSklJCXtOenq6/H7/175mRUWFPB6Ps2VlZfV22QAAwCK9fopnzpw5zt+5ubnKy8vTqFGj9Nprr2ngwIHdes3y8nKVlZU5j4PBICEFAIB+7KpfZpySkqJvfvObOnr0qLxer9rb29Xc3BzWp7Gx8ZJrVi5KTk6W2+0O2wAAQP911QPK+fPndezYMWVkZGjKlClKTExUVVWV015fX6+Ghgb5fL6rXQoAAOgjev0Uz89+9jPdeeedGjVqlE6ePKnHHntM8fHxuv/+++XxeLRo0SKVlZUpNTVVbrdbDz30kHw+H1fwAAAAR68HlE8++UT333+/zpw5oxEjRui2227T7t27NWLECEnSM888o7i4OBUVFamtrU0FBQV66aWXersMAADQh7mMMSbWRUQqGAzK4/EoEAiwHgUAgD4iku9vfosHAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCdiAPKrl27dOeddyozM1Mul0tvvPFGWLsxRo8++qgyMjI0cOBA5efn6+OPPw7rc/bsWc2fP19ut1spKSlatGiRzp8/36MDAQAA/UfEAaWlpUWTJ0/Wiy++eMn2NWvW6Pnnn9e6deu0Z88eDR48WAUFBWptbXX6zJ8/X4cOHVJlZaW2bNmiXbt2acmSJd0/CgAA0K+4jDGm2092ubR582bNmzdP0uezJ5mZmXr44Yf1s5/9TJIUCASUnp6u9evX67777tNHH32knJwc7d27V1OnTpUkbdu2TXPnztUnn3yizMzMK75vMBiUx+NRIBCQ2+3ubvkAACCKIvn+7tU1KMePH5ff71d+fr6zz+PxKC8vTzU1NZKkmpoapaSkOOFEkvLz8xUXF6c9e/Zc8nXb2toUDAbDNgAA0H/1akDx+/2SpPT09LD96enpTpvf71daWlpYe0JCglJTU50+X1ZRUSGPx+NsWVlZvVk2AACwTJ+4iqe8vFyBQMDZTpw4EeuSAADAVdSrAcXr9UqSGhsbw/Y3NjY6bV6vV01NTWHtHR0dOnv2rNPny5KTk+V2u8M2AADQf/VqQBk9erS8Xq+qqqqcfcFgUHv27JHP55Mk+Xw+NTc3q7a21umzY8cOhUIh5eXl9WY5AACgj0qI9Annz5/X0aNHncfHjx9XXV2dUlNTlZ2drWXLlulv/uZvNHbsWI0ePVq//OUvlZmZ6VzpM2HCBM2ePVuLFy/WunXrdOHCBZWWluq+++7r0hU8AACg/4s4oHz44Yf63ve+5zwuKyuTJBUXF2v9+vX6+c9/rpaWFi1ZskTNzc267bbbtG3bNg0YMMB5zquvvqrS0lLNnDlTcXFxKioq0vPPP98LhwMAAPqDHt0HJVa4DwoAAH1PzO6DAgAA0BsIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBNxQNm1a5fuvPNOZWZmyuVy6Y033ghrf+CBB+RyucK22bNnh/U5e/as5s+fL7fbrZSUFC1atEjnz5/v0YEAAID+I+KA0tLSosmTJ+vFF1/82j6zZ8/WqVOnnO3Xv/51WPv8+fN16NAhVVZWasuWLdq1a5eWLFkSefUAAKBfSoj0CXPmzNGcOXMu2yc5OVler/eSbR999JG2bdumvXv3aurUqZKkF154QXPnztXf/d3fKTMzM9KSAABAP3NV1qDs3LlTaWlpGjdunJYuXaozZ844bTU1NUpJSXHCiSTl5+crLi5Oe/bsueTrtbW1KRgMhm0AAKD/6vWAMnv2bP3Lv/yLqqqq9Ld/+7eqrq7WnDlz1NnZKUny+/1KS0sLe05CQoJSU1Pl9/sv+ZoVFRXyeDzOlpWV1dtlAwAAi0R8iudK7rvvPufvSZMmKTc3VzfeeKN27typmTNndus1y8vLVVZW5jwOBoOEFAAA+rGrfpnxDTfcoOHDh+vo0aOSJK/Xq6amprA+HR0dOnv27NeuW0lOTpbb7Q7bAABA/3XVA8onn3yiM2fOKCMjQ5Lk8/nU3Nys2tpap8+OHTsUCoWUl5d3tcsBAAB9QMSneM6fP+/MhkjS8ePHVVdXp9TUVKWmpmr16tUqKiqS1+vVsWPH9POf/1xjxoxRQUGBJGnChAmaPXu2Fi9erHXr1unChQsqLS3VfffdxxU8AABAkuQyxphInrBz505973vf+8r+4uJirV27VvPmzdO+ffvU3NyszMxMzZo1S7/61a+Unp7u9D179qxKS0v11ltvKS4uTkVFRXr++ec1ZMiQLtUQDAbl8XgUCAQ43QMAQB8Ryfd3xAHFBgQUAAD6nki+v/ktHgAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwTsQ/FggA3WGM0bF3/q9CHe2X7Xf9dxcqaZAnSlUBsBUBBUDUBE8cUueF1sv2CbW3ygx0y+VyRakqADbiFA8AqxjTGesSAFiAgALAKiYUinUJACxAQAFgFRNiBgUAAQWAZYxhBgUAAQWAZZhBASARUABYhoACQCKgALAMi2QBSAQUAJZhDQoAiYACwDbMoAAQAQWAZbhRGwCJgALAMiySBSARUABYhkWyACQCCgDLEFAASAQUALZhDQoAEVAAWIY1KAAkAgoAyxBQAEgEFACW4UZtACQCCgDLsEgWgBRhQKmoqNC0adM0dOhQpaWlad68eaqvrw/r09raqpKSEg0bNkxDhgxRUVGRGhsbw/o0NDSosLBQgwYNUlpamlasWKGOjo6eHw2APo9TPACkCANKdXW1SkpKtHv3blVWVurChQuaNWuWWlpanD7Lly/XW2+9pU2bNqm6ulonT57U3Xff7bR3dnaqsLBQ7e3tev/99/XKK69o/fr1evTRR3vvqAD0WZziASBJLmOM6e6TT58+rbS0NFVXV+v2229XIBDQiBEjtGHDBt1zzz2SpCNHjmjChAmqqanR9OnTtXXrVt1xxx06efKk0tPTJUnr1q3TypUrdfr0aSUlJV3xfYPBoDwejwKBgNxud3fLBxBFxhjte/mn6rzQetl+mVN/qMxvF8rlckWpMgDREsn3d4/WoAQCAUlSamqqJKm2tlYXLlxQfn6+02f8+PHKzs5WTU2NJKmmpkaTJk1ywokkFRQUKBgM6tChQ5d8n7a2NgWDwbANQP/EGhQAUg8CSigU0rJly3Trrbdq4sSJkiS/36+kpCSlpKSE9U1PT5ff73f6fDGcXGy/2HYpFRUV8ng8zpaVldXdsgFY7vM1KN2e2AXQT3Q7oJSUlOjgwYPauHFjb9ZzSeXl5QoEAs524sSJq/6eAGKDRbIApG4GlNLSUm3ZskXvvvuuRo4c6ez3er1qb29Xc3NzWP/GxkZ5vV6nz5ev6rn4+GKfL0tOTpbb7Q7bAPQ98QMGX7FPR+v5KFQCwHYRBRRjjEpLS7V582bt2LFDo0ePDmufMmWKEhMTVVVV5eyrr69XQ0ODfD6fJMnn8+nAgQNqampy+lRWVsrtdisnJ6cnxwLAcsPH3XbFPmc+3i11f+0+gH4iIZLOJSUl2rBhg958800NHTrUWTPi8Xg0cOBAeTweLVq0SGVlZUpNTZXb7dZDDz0kn8+n6dOnS5JmzZqlnJwcLViwQGvWrJHf79eqVatUUlKi5OTk3j9CANaIi+PekAC6JqKAsnbtWknSjBkzwva//PLLeuCBByRJzzzzjOLi4lRUVKS2tjYVFBTopZdecvrGx8dry5YtWrp0qXw+nwYPHqzi4mI98cQTPTsSANZzxcXHugQAfUSP7oMSK9wHBeh7jDFqPFClEzWvXb6jK05T/8+LhBmgH4rafVAAIBKEDgBdRUABEDUu1qAA6CI+LQBEjcvFDAqAriGgAIgaVzwBBUDXEFAARA2neAB0FZ8WAKKHUzwAuoiAAiBqmEEB0FV8WgCIGhbJAugqAgqAqGEGBUBX8WkBIGq4URuAriKgAIgaTvEA6CoCCoCo4RQPgK7i0wJA1HCKB0BXEVAARA0BBUBXEVAARA1rUAB0FQEFQPSwBgVAF/FpASBqWCQLoKv4tAAQNaxBAdBVBBQAUcMaFABdRUABEDWc4gHQVXxaAIgaTvEA6CoCCoCocLlcXZ5BMVe5FgD2I6AAsI4JhWJdAoAYI6AAsI/pjHUFAGKMgALAOsygACCgALCOCTGDAlzrCCgArMMMCgACCgDrGNagANc8AgoA+zCDAlzzCCgArMMaFAAEFACWMTKGGRTgWhdRQKmoqNC0adM0dOhQpaWlad68eaqvrw/rM2PGjM/vGPmF7cEHHwzr09DQoMLCQg0aNEhpaWlasWKFOjo6en40APoFZlAAJETSubq6WiUlJZo2bZo6Ojr0i1/8QrNmzdLhw4c1ePBgp9/ixYv1xBNPOI8HDRrk/N3Z2anCwkJ5vV69//77OnXqlBYuXKjExEQ9+eSTvXBIAPo6ZlAARBRQtm3bFvZ4/fr1SktLU21trW6//XZn/6BBg+T1ei/5Gr///e91+PBhvfPOO0pPT9fNN9+sX/3qV1q5cqUef/xxJSUldeMwAPQnzKAA6NEalEAgIElKTU0N2//qq69q+PDhmjhxosrLy/Xpp586bTU1NZo0aZLS09OdfQUFBQoGgzp06NAl36etrU3BYDBsA9B/cR8UABHNoHxRKBTSsmXLdOutt2rixInO/h/96EcaNWqUMjMztX//fq1cuVL19fV6/fXXJUl+vz8snEhyHvv9/ku+V0VFhVavXt3dUgH0McygAOh2QCkpKdHBgwf13nvvhe1fsmSJ8/ekSZOUkZGhmTNn6tixY7rxxhu79V7l5eUqKytzHgeDQWVlZXWvcADWYw0KgG6d4iktLdWWLVv07rvvauTIkZftm5eXJ0k6evSoJMnr9aqxsTGsz8XHX7duJTk5WW63O2wD0H9xigdARAHFGKPS0lJt3rxZO3bs0OjRo6/4nLq6OklSRkaGJMnn8+nAgQNqampy+lRWVsrtdisnJyeScgD0U5ziARDRKZ6SkhJt2LBBb775poYOHeqsGfF4PBo4cKCOHTumDRs2aO7cuRo2bJj279+v5cuX6/bbb1dubq4kadasWcrJydGCBQu0Zs0a+f1+rVq1SiUlJUpOTu79IwTQ9xBQgGteRDMoa9euVSAQ0IwZM5SRkeFsv/nNbyRJSUlJeueddzRr1iyNHz9eDz/8sIqKivTWW285rxEfH68tW7YoPj5ePp9PP/7xj7Vw4cKw+6YAuLbxY4EAIppBMcZctj0rK0vV1dVXfJ1Ro0bp7bffjuStAVwrDGtQAPBbPAAsxFU8AAgoAKzDIlkABBQA9uEUD3DNI6AAsA6LZAEQUABYh0WyAAgoAKImLj5Rw8bkXaGX0enDV74aEED/RkABEEUuuRKvfEPGUOeFKNQCwGYEFABR5XLxsQPgyvikABBVrjg+dgBcGZ8UAKLHxQwKgK7hkwJAVLni4mNdAoA+gIACIIpcEjMoALqATwoAUcUaFABdwScFgKjiFA+AriCgAIgqFskC6Ao+KQBEFad4AHQFnxQAosflYgYFQJfwSQEgalySxBoUAF1AQAEQVcygAOiKhFgXAKBv6ejo6PZzTSgkY7rQz5gevY8kxcXFKY71LkCfRUABEJGbb75Z9fX13XpufJxLc24Zo1/8+LbL9vvP//xPTR04sFvvcdHGjRtVVFTUo9cAEDsEFAAR6ezs7PbsRsjlUnsXn9vTGZRQKNSj5wOILQIKgKjq/EJwONOeoUDHCHUqQQPiWjQiqUED4j6LYXUAbEFAARA1RkadnZ8vQvnPT3N1onWCPgsNllG8Elxt+qR1nL7lrpQUjG2hAGKOFWQAoqozZNTw2QR9/OlUfRryyChBkksdZoCaO7x6v/ludRouRQaudQQUAFF1pm2EDrXcptDXTOC2hQbpvf+9J8pVAbANAQVA9BipI2T0/2/Z9jUu1wbgWkFAARA1Rp+f4gGAKyGgAIiqzk4u/wVwZQQUAFE1NL5R4wbtlkuXDioJrnb5Ut6MclUAbBNRQFm7dq1yc3Pldrvldrvl8/m0detWp721tVUlJSUaNmyYhgwZoqKiIjU2Noa9RkNDgwoLCzVo0CClpaVpxYoVPb4hE4C+w4Q6NXrgft0wsE7JcS1yqVOSUbzaNTj+f/WdlE1KimuNdZkAYiyi+6CMHDlSTz31lMaOHStjjF555RXddddd2rdvn2666SYtX75cv/vd77Rp0yZ5PB6Vlpbq7rvv1h/+8AdJn9+BsrCwUF6vV++//75OnTqlhQsXKjExUU8++eRVOUAAdvlT4FO9+Ycjko6oqT1bZy9kqNMkamB8UJlJx7QtvkX/e46btQHXOpcxXfnprq+Xmpqqp59+Wvfcc49GjBihDRs26J57Pr9E8MiRI5owYYJqamo0ffp0bd26VXfccYdOnjyp9PR0SdK6deu0cuVKnT59WklJSV16z2AwKI/HowceeKDLzwHQO1577TU1NzfHuowrys/P1w033BDrMgB8QXt7u9avX69AICC3233Zvt2+k2xnZ6c2bdqklpYW+Xw+1dbW6sKFC8rPz3f6jB8/XtnZ2U5Aqamp0aRJk5xwIkkFBQVaunSpDh06pG9961uXfK+2tja1tbU5j4PBz+8yuWDBAg0ZMqS7hwCgG7Zv394nAsrMmTP1/e9/P9ZlAPiC8+fPa/369V3qG3FAOXDggHw+n1pbWzVkyBBt3rxZOTk5qqurU1JSklJSUsL6p6eny+/3S5L8fn9YOLnYfrHt61RUVGj16tVf2T916tQrJjAAvWtgD39lOFpuvPFG3XLLLbEuA8AXXJxg6IqIr+IZN26c6urqtGfPHi1dulTFxcU6fPhwpC8TkfLycgUCAWc7ceLEVX0/AAAQWxHPoCQlJWnMmDGSpClTpmjv3r167rnndO+996q9vV3Nzc1hsyiNjY3yer2SJK/Xqw8++CDs9S5e5XOxz6UkJycrOTk50lIBAEAf1eP7oIRCIbW1tWnKlClKTExUVVWV01ZfX6+Ghgb5fD5Jks/n04EDB9TU1OT0qayslNvtVk5OTk9LAQAA/UREMyjl5eWaM2eOsrOzde7cOW3YsEE7d+7U9u3b5fF4tGjRIpWVlSk1NVVut1sPPfSQfD6fpk+fLkmaNWuWcnJytGDBAq1Zs0Z+v1+rVq1SSUkJMyQAAMARUUBpamrSwoULderUKXk8HuXm5mr79u36wQ9+IEl65plnFBcXp6KiIrW1tamgoEAvvfSS8/z4+Hht2bJFS5culc/n0+DBg1VcXKwnnniid48KAAD0aT2+D0osXLwPSleuowbQuyZMmKAjR47Euowreu211/QXf/EXsS4DwBdE8v3Nb/EAAADrEFAAAIB1CCgAAMA6BBQAAGCdbv8WD4BrU35+vsaPHx/rMq7ouuuui3UJAHqAgAIgIi+88EKsSwBwDeAUDwAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ2IAsratWuVm5srt9stt9stn8+nrVu3Ou0zZsyQy+UK2x588MGw12hoaFBhYaEGDRqktLQ0rVixQh0dHb1zNAAAoF9IiKTzyJEj9dRTT2ns2LEyxuiVV17RXXfdpX379ummm26SJC1evFhPPPGE85xBgwY5f3d2dqqwsFBer1fvv/++Tp06pYULFyoxMVFPPvlkLx0SAADo61zGGNOTF0hNTdXTTz+tRYsWacaMGbr55pv17LPPXrLv1q1bdccdd+jkyZNKT0+XJK1bt04rV67U6dOnlZSU1KX3DAaD8ng8CgQCcrvdPSkfAABESSTf391eg9LZ2amNGzeqpaVFPp/P2f/qq69q+PDhmjhxosrLy/Xpp586bTU1NZo0aZITTiSpoKBAwWBQhw4d+tr3amtrUzAYDNsAAED/FdEpHkk6cOCAfD6fWltbNWTIEG3evFk5OTmSpB/96EcaNWqUMjMztX//fq1cuVL19fV6/fXXJUl+vz8snEhyHvv9/q99z4qKCq1evTrSUgEAQB8VcUAZN26c6urqFAgE9Nvf/lbFxcWqrq5WTk6OlixZ4vSbNGmSMjIyNHPmTB07dkw33nhjt4ssLy9XWVmZ8zgYDCorK6vbrwcAAOwW8SmepKQkjRkzRlOmTFFFRYUmT56s55577pJ98/LyJElHjx6VJHm9XjU2Nob1ufjY6/V+7XsmJyc7Vw5d3AAAQP/V4/ughEIhtbW1XbKtrq5OkpSRkSFJ8vl8OnDggJqampw+lZWVcrvdzmkiAACAiE7xlJeXa86cOcrOzta5c+e0YcMG7dy5U9u3b9exY8e0YcMGzZ07V8OGDdP+/fu1fPly3X777crNzZUkzZo1Szk5OVqwYIHWrFkjv9+vVatWqaSkRMnJyVflAAEAQN8TUUBpamrSwoULderUKXk8HuXm5mr79u36wQ9+oBMnTuidd97Rs88+q5aWFmVlZamoqEirVq1ynh8fH68tW7Zo6dKl8vl8Gjx4sIqLi8PumwIAANDj+6DEAvdBAQCg74nKfVAAAACuFgIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGCdhFgX0B3GGElSMBiMcSUAAKCrLn5vX/wev5w+GVDOnTsnScrKyopxJQAAIFLnzp2Tx+O5bB+X6UqMsUwoFFJ9fb1ycnJ04sQJud3uWJfUZwWDQWVlZTGOvYCx7D2MZe9gHHsPY9k7jDE6d+6cMjMzFRd3+VUmfXIGJS4uTtddd50kye1288/SCxjH3sNY9h7Gsncwjr2Hsey5K82cXMQiWQAAYB0CCgAAsE6fDSjJycl67LHHlJycHOtS+jTGsfcwlr2HsewdjGPvYSyjr08ukgUAAP1bn51BAQAA/RcBBQAAWIeAAgAArENAAQAA1umTAeXFF1/U9ddfrwEDBigvL08ffPBBrEuyzq5du3TnnXcqMzNTLpdLb7zxRli7MUaPPvqoMjIyNHDgQOXn5+vjjz8O63P27FnNnz9fbrdbKSkpWrRokc6fPx/Fo4i9iooKTZs2TUOHDlVaWprmzZun+vr6sD6tra0qKSnRsGHDNGTIEBUVFamxsTGsT0NDgwoLCzVo0CClpaVpxYoV6ujoiOahxNTatWuVm5vr3OTK5/Np69atTjtj2H1PPfWUXC6Xli1b5uxjPLvm8ccfl8vlCtvGjx/vtDOOMWb6mI0bN5qkpCTzz//8z+bQoUNm8eLFJiUlxTQ2Nsa6NKu8/fbb5q//+q/N66+/biSZzZs3h7U/9dRTxuPxmDfeeMP8+7//u/nhD39oRo8ebT777DOnz+zZs83kyZPN7t27zb/927+ZMWPGmPvvvz/KRxJbBQUF5uWXXzYHDx40dXV1Zu7cuSY7O9ucP3/e6fPggw+arKwsU1VVZT788EMzffp082d/9mdOe0dHh5k4caLJz883+/btM2+//bYZPny4KS8vj8UhxcS//uu/mt/97nfmP/7jP0x9fb35xS9+YRITE83BgweNMYxhd33wwQfm+uuvN7m5ueanP/2ps5/x7JrHHnvM3HTTTebUqVPOdvr0aaedcYytPhdQbrnlFlNSUuI87uzsNJmZmaaioiKGVdntywElFAoZr9drnn76aWdfc3OzSU5ONr/+9a+NMcYcPnzYSDJ79+51+mzdutW4XC7zP//zP1Gr3TZNTU1GkqmurjbGfD5uiYmJZtOmTU6fjz76yEgyNTU1xpjPw2JcXJzx+/1On7Vr1xq3223a2tqiewAW+cY3vmH+8R//kTHspnPnzpmxY8eayspK893vftcJKIxn1z322GNm8uTJl2xjHGOvT53iaW9vV21trfLz8519cXFxys/PV01NTQwr61uOHz8uv98fNo4ej0d5eXnOONbU1CglJUVTp051+uTn5ysuLk579uyJes22CAQCkqTU1FRJUm1trS5cuBA2luPHj1d2dnbYWE6aNEnp6elOn4KCAgWDQR06dCiK1duhs7NTGzduVEtLi3w+H2PYTSUlJSosLAwbN4n/yUh9/PHHyszM1A033KD58+eroaFBEuNogz71Y4F/+tOf1NnZGfbPIEnp6ek6cuRIjKrqe/x+vyRdchwvtvn9fqWlpYW1JyQkKDU11elzrQmFQlq2bJluvfVWTZw4UdLn45SUlKSUlJSwvl8ey0uN9cW2a8WBAwfk8/nU2tqqIUOGaPPmzcrJyVFdXR1jGKGNGzfqj3/8o/bu3fuVNv4nuy4vL0/r16/XuHHjdOrUKa1evVrf+c53dPDgQcbRAn0qoACxVFJSooMHD+q9996LdSl90rhx41RXV6dAIKDf/va3Ki4uVnV1dazL6nNOnDihn/70p6qsrNSAAQNiXU6fNmfOHOfv3Nxc5eXladSoUXrttdc0cODAGFYGqY9dxTN8+HDFx8d/ZRV1Y2OjvF5vjKrqey6O1eXG0ev1qqmpKay9o6NDZ8+evSbHurS0VFu2bNG7776rkSNHOvu9Xq/a29vV3Nwc1v/LY3mpsb7Ydq1ISkrSmDFjNGXKFFVUVGjy5Ml67rnnGMMI1dbWqqmpSd/+9reVkJCghIQEVVdX6/nnn1dCQoLS09MZz25KSUnRN7/5TR09epT/Swv0qYCSlJSkKVOmqKqqytkXCoVUVVUln88Xw8r6ltGjR8vr9YaNYzAY1J49e5xx9Pl8am5uVm1trdNnx44dCoVCysvLi3rNsWKMUWlpqTZv3qwdO3Zo9OjRYe1TpkxRYmJi2FjW19eroaEhbCwPHDgQFvgqKyvldruVk5MTnQOxUCgUUltbG2MYoZkzZ+rAgQOqq6tztqlTp2r+/PnO34xn95w/f17Hjh1TRkYG/5c2iPUq3Uht3LjRJCcnm/Xr15vDhw+bJUuWmJSUlLBV1Ph8hf++ffvMvn37jCTz93//92bfvn3mv//7v40xn19mnJKSYt58802zf/9+c9ddd13yMuNvfetbZs+ePea9994zY8eOveYuM166dKnxeDxm586dYZcifvrpp06fBx980GRnZ5sdO3aYDz/80Ph8PuPz+Zz2i5cizpo1y9TV1Zlt27aZESNGXFOXIj7yyCOmurraHD9+3Ozfv9888sgjxuVymd///vfGGMawp754FY8xjGdXPfzww2bnzp3m+PHj5g9/+IPJz883w4cPN01NTcYYxjHW+lxAMcaYF154wWRnZ5ukpCRzyy23mN27d8e6JOu8++67RtJXtuLiYmPM55ca//KXvzTp6ekmOTnZzJw509TX14e9xpkzZ8z9999vhgwZYtxut/nJT35izp07F4OjiZ1LjaEk8/LLLzt9PvvsM/NXf/VX5hvf+IYZNGiQ+fM//3Nz6tSpsNf5r//6LzNnzhwzcOBAM3z4cPPwww+bCxcuRPloYucv//IvzahRo0xSUpIZMWKEmTlzphNOjGEMe+rLAYXx7Jp7773XZGRkmKSkJHPdddeZe++91xw9etRpZxxjy2WMMbGZuwEAALi0PrUGBQAAXBsIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwzv8DDfygSVixY6EAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75eHkuwTi2Si"
      },
      "source": [
        "# Building the network for Policy Gradient (REINFORCE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_TFCmsWi2Sj"
      },
      "source": [
        "For REINFORCE algorithm, we'll need a model that predicts action probabilities given states.\n",
        "\n",
        "For numerical stability, please __do not include the softmax layer into your network architecture__.\n",
        "We'll use softmax or log-softmax where appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "sY2THBWfi2Sl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "8_pYr7PZi2Sn"
      },
      "outputs": [],
      "source": [
        "# Build a simple neural network that predicts policy logits.\n",
        "# Keep it simple: CartPole isn't worth deep architectures.\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(state_dim[0], 32),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.GELU(),\n",
        "    nn.Linear(16, n_actions)\n",
        ")\n",
        "assert model is not None, \"model is not defined\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-e_RefALorG",
        "outputId": "1b50958a-28b1-4469-8aa0-e668f47fb8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example_states_batch.shape: (5, 4)\n",
            "example_logits.shape: torch.Size([5, 2])\n"
          ]
        }
      ],
      "source": [
        "# do not change the code block below\n",
        "batch_size_for_test = 5\n",
        "example_states_batch = np.array([env.reset()[0] for _ in range(5)])\n",
        "print(f\"example_states_batch.shape: {example_states_batch.shape}\")\n",
        "assert example_states_batch.shape == (batch_size_for_test, state_dim[0])\n",
        "\n",
        "example_logits = model(torch.from_numpy(example_states_batch))\n",
        "print(f\"example_logits.shape: {example_logits.shape}\")\n",
        "assert example_logits.shape == (batch_size_for_test, n_actions)\n",
        "# do not change the code block above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y80qbQFi2Sq"
      },
      "source": [
        "#### Predicting the action probas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12PjRu0mi2Sr"
      },
      "source": [
        "Note: **output value of this function is not a torch tensor, it's a numpy array.**\n",
        "\n",
        "So, here gradient calculation is not needed.\n",
        "\n",
        "Use [no_grad](https://pytorch.org/docs/stable/autograd.html#torch.autograd.no_grad)\n",
        "to suppress gradient calculation.\n",
        "\n",
        "Also, `.detach()` can be used instead, but there is a difference:\n",
        "\n",
        "* With `.detach()` computational graph is built but then disconnected from a particular tensor, so `.detach()` should be used if that graph is needed for backprop via some other (not detached) tensor;\n",
        "* In contrast, no graph is built by any operation in `no_grad()` context, thus it's preferable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "d5B5JuXCi2St"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_probs(states):\n",
        "    \"\"\"\n",
        "    Predict action probabilities given states.\n",
        "    :param states: numpy array [batch, state_dim] или torch.Tensor\n",
        "    :returns: numpy array [batch, n_actions]\n",
        "    \"\"\"\n",
        "    if isinstance(states, np.ndarray) and states.ndim == 1:\n",
        "        states = states[None, :]\n",
        "    if torch.is_tensor(states) and states.ndim == 1:\n",
        "        states = states.unsqueeze(0)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        x = states if torch.is_tensor(states) else torch.as_tensor(states)\n",
        "        logits = model(x)\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        return probs.detach().cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "Obkl_jCii2Sv"
      },
      "outputs": [],
      "source": [
        "test_states = np.array([env.reset()[0] for _ in range(5)])\n",
        "test_probas = predict_probs(test_states)\n",
        "assert isinstance(test_probas, np.ndarray), \\\n",
        "    \"you must return np array and not %s\" % type(test_probas)\n",
        "assert tuple(test_probas.shape) == (test_states.shape[0], env.action_space.n), \\\n",
        "    \"wrong output shape: %s\" % np.shape(test_probas)\n",
        "assert np.allclose(np.sum(test_probas, axis=1), 1), \"probabilities do not sum to 1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be6AYf8gi2Sw"
      },
      "source": [
        "### Play the game\n",
        "\n",
        "We can now use our newly built agent to play the game."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8LOUUvnki2Sx"
      },
      "outputs": [],
      "source": [
        "def generate_session(env, t_max=1000):\n",
        "    \"\"\"\n",
        "    Play a full session with REINFORCE agent.\n",
        "    Returns sequences of states, actions, and rewards.\n",
        "    \"\"\"\n",
        "    # arrays to record session\n",
        "    states, actions, rewards = [], [], []\n",
        "    s, info = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # action probabilities array aka pi(a|s)\n",
        "        action_probs = predict_probs(np.array([s]))[0]\n",
        "\n",
        "        # Sample action with given probabilities.\n",
        "        a = np.random.choice(n_actions, p=action_probs)\n",
        "        new_s, r, done, truncated, info = env.step(a)\n",
        "\n",
        "        # record session history to train later\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return states, actions, rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "5sdENWJAi2Sz"
      },
      "outputs": [],
      "source": [
        "# test it\n",
        "states, actions, rewards = generate_session(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG5hLg-3i2S0"
      },
      "source": [
        "### Computing cumulative rewards\n",
        "\n",
        "To work with sequential environments we need the cumulative discounted reward for known for every state. To compute it we can **roll back** from the end of the session to the beginning and compute the discounted cumulative reward as following:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "G_t &= r_t + \\gamma r_{t + 1} + \\gamma^2 r_{t + 2} + \\ldots \\\\\n",
        "&= \\sum_{i = t}^T \\gamma^{i - t} r_i \\\\\n",
        "&= r_t + \\gamma * G_{t + 1}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "AoWX9gvai2S0"
      },
      "outputs": [],
      "source": [
        "def get_cumulative_rewards(rewards,  # rewards at each step\n",
        "                           gamma=0.99  # discount for reward\n",
        "                           ):\n",
        "    \"\"\"\n",
        "    Take a list of immediate rewards r(s,a) for the whole session\n",
        "    and compute cumulative returns (a.k.a. G(s,a) in Sutton '16).\n",
        "\n",
        "    G_t = r_t + gamma*r_{t+1} + gamma^2*r_{t+2} + ...\n",
        "\n",
        "    A simple way to compute cumulative rewards is to iterate from the last\n",
        "    to the first timestep and compute G_t = r_t + gamma*G_{t+1} recurrently\n",
        "\n",
        "    You must return an array/list of cumulative rewards with as many elements as in the initial rewards.\n",
        "    \"\"\"\n",
        "    # YOUR CODE GOES HERE\n",
        "\n",
        "    T = len(rewards)\n",
        "    G = 0.0\n",
        "    cumulative_rewards = np.zeros(T, dtype=np.float32)\n",
        "    for t in range(T - 1, -1, -1):\n",
        "        G = rewards[t] + gamma * G\n",
        "        cumulative_rewards[t] = G\n",
        "\n",
        "    assert cumulative_rewards is not None, \"cumulative_rewards is not defined\"\n",
        "\n",
        "    return cumulative_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DX39wcUi2S3",
        "outputId": "3ac0897f-ad43-4af4-a1e7-9d38abd67680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "looks good!\n"
          ]
        }
      ],
      "source": [
        "get_cumulative_rewards(rewards)\n",
        "assert len(get_cumulative_rewards(list(range(100)))) == 100\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 0, 0, 1, 0], gamma=0.9),\n",
        "    [1.40049, 1.5561, 1.729, 0.81, 0.9, 1.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, -2, 3, -4, 0], gamma=0.5),\n",
        "    [0.0625, 0.125, 0.25, -1.5, 1.0, -4.0, 0.0])\n",
        "assert np.allclose(\n",
        "    get_cumulative_rewards([0, 0, 1, 2, 3, 4, 0], gamma=0),\n",
        "    [0, 0, 1, 2, 3, 4, 0])\n",
        "print(\"looks good!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evLt5DJji2S_"
      },
      "source": [
        "### Loss function and updates\n",
        "\n",
        "We now need to define objective and update over policy gradient.\n",
        "\n",
        "Our objective function is\n",
        "\n",
        "$$ J \\approx  { 1 \\over N } \\sum_{s_i,a_i} G(s_i,a_i) $$\n",
        "\n",
        "REINFORCE defines a way to compute the gradient of the expected reward with respect to policy parameters. The formula is as follows:\n",
        "\n",
        "$$ \\nabla_\\theta \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\nabla_\\theta \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "We can abuse PyTorch's capabilities for automatic differentiation by defining our objective function as follows:\n",
        "\n",
        "$$ \\hat J(\\theta) \\approx { 1 \\over N } \\sum_{s_i, a_i} \\log \\pi_\\theta (a_i \\mid s_i) \\cdot G_t(s_i, a_i) $$\n",
        "\n",
        "When you compute the gradient of that function with respect to network weights $\\theta$, it will become exactly the policy gradient.\n",
        "\n",
        "Final loss should also include the entropy regularization term $H(\\pi_\\theta (a_i \\mid s_i))$ to enforce the exploration:\n",
        "\n",
        "$$\n",
        "L = -\\hat J(\\theta) - \\lambda H(\\pi_\\theta (a_i \\mid s_i)),\n",
        "$$\n",
        "where $\\lambda$ is the `entropy_coef`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbwDRp44LorH"
      },
      "source": [
        "This function might be useful:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "_hLjxTVLi2TB"
      },
      "outputs": [],
      "source": [
        "def to_one_hot(y_tensor, ndims):\n",
        "    \"\"\" helper: take an integer vector and convert it to 1-hot matrix. \"\"\"\n",
        "    y_tensor = y_tensor.type(torch.LongTensor).view(-1, 1)\n",
        "    y_one_hot = torch.zeros(\n",
        "        y_tensor.size()[0], ndims).scatter_(1, y_tensor, 1)\n",
        "    return y_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Oq6r-t5YLorH"
      },
      "outputs": [],
      "source": [
        "def get_loss(logits, actions, rewards, n_actions=n_actions, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Compute the loss for the REINFORCE algorithm.\n",
        "    \"\"\"\n",
        "    actions = torch.tensor(actions, dtype=torch.int32)\n",
        "    cumulative_returns = np.array(get_cumulative_rewards(rewards, gamma))\n",
        "    cumulative_returns = torch.tensor(cumulative_returns, dtype=torch.float32)\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    assert probs is not None, \"probs is not defined\"\n",
        "\n",
        "    log_probs = F.log_softmax(logits, dim=-1)\n",
        "    assert log_probs is not None, \"log_probs is not defined\"\n",
        "\n",
        "    assert all(isinstance(v, torch.Tensor) for v in [logits, probs, log_probs]), \\\n",
        "        \"please use compute using torch tensors and don't use predict_probs function\"\n",
        "\n",
        "    # select log-probabilities for chosen actions, log pi(a_i|s_i)\n",
        "    log_probs_for_actions = log_probs.gather(1, actions.long().view(-1, 1)).squeeze(1)  # [B]\n",
        "    assert log_probs_for_actions is not None, \"log_probs_for_actions is not defined\"\n",
        "    J_hat = (log_probs_for_actions * cumulative_returns).mean()  # a number\n",
        "    assert J_hat is not None, \"J_hat is not defined\"\n",
        "\n",
        "    # Compute loss here. Don't forget entropy regularization with `entropy_coef`\n",
        "    entropy = entropy_coef * (-(probs * log_probs).sum(dim=-1).mean())\n",
        "    assert entropy is not None, \"entropy is not defined\"\n",
        "    loss = -J_hat - entropy\n",
        "    assert loss is not None, \"loss is not defined\"\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "1C8ZSizji2TD"
      },
      "outputs": [],
      "source": [
        "# Your code: define optimizers\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "def train_on_session(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
        "    \"\"\"\n",
        "    Takes a sequence of states, actions and rewards produced by generate_session.\n",
        "    Updates agent's weights by following the policy gradient above.\n",
        "    Please use Adam optimizer with default parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    states = torch.tensor(states, dtype=torch.float32)\n",
        "    logits = model(states)\n",
        "    # cast everything into torch tensors\n",
        "    loss = get_loss(logits, actions, rewards, n_actions=n_actions, gamma=gamma, entropy_coef=entropy_coef)\n",
        "    # Gradient descent step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # technical: return session rewards to print them later\n",
        "    return np.sum(rewards)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-WWsbl5i2TE"
      },
      "source": [
        "### The actual training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckHj5sXBi2TE",
        "outputId": "c1ecdcd6-21ff-4334-c1b7-330eaf5525ab",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean reward:21.060\n",
            "mean reward:25.460\n",
            "mean reward:33.100\n",
            "mean reward:38.640\n",
            "mean reward:59.920\n",
            "mean reward:81.990\n",
            "mean reward:160.740\n",
            "mean reward:164.090\n",
            "mean reward:132.290\n",
            "mean reward:147.940\n",
            "mean reward:190.050\n",
            "mean reward:315.100\n",
            "mean reward:141.800\n",
            "mean reward:104.090\n",
            "mean reward:220.180\n",
            "mean reward:132.870\n",
            "mean reward:160.830\n",
            "mean reward:155.650\n",
            "mean reward:211.770\n",
            "mean reward:156.380\n",
            "mean reward:117.070\n",
            "mean reward:112.630\n",
            "mean reward:142.720\n",
            "mean reward:135.300\n",
            "mean reward:204.460\n",
            "mean reward:217.770\n",
            "mean reward:140.870\n",
            "mean reward:188.310\n",
            "mean reward:93.490\n",
            "mean reward:91.730\n",
            "mean reward:104.910\n",
            "mean reward:280.450\n",
            "mean reward:168.020\n",
            "mean reward:120.590\n",
            "mean reward:113.740\n",
            "mean reward:134.920\n",
            "mean reward:121.800\n",
            "mean reward:223.730\n",
            "mean reward:187.780\n",
            "mean reward:136.860\n",
            "mean reward:152.470\n",
            "mean reward:137.120\n",
            "mean reward:108.340\n",
            "mean reward:97.020\n",
            "mean reward:107.100\n",
            "mean reward:113.700\n",
            "mean reward:110.850\n",
            "mean reward:122.850\n",
            "mean reward:139.790\n",
            "mean reward:161.320\n",
            "mean reward:421.810\n",
            "mean reward:331.540\n",
            "mean reward:400.810\n",
            "mean reward:302.970\n",
            "mean reward:222.250\n",
            "mean reward:121.190\n",
            "mean reward:257.300\n",
            "mean reward:448.320\n",
            "mean reward:601.020\n",
            "mean reward:127.420\n",
            "mean reward:106.660\n",
            "mean reward:108.130\n",
            "mean reward:108.700\n",
            "mean reward:116.420\n",
            "mean reward:116.020\n",
            "mean reward:109.450\n",
            "mean reward:106.450\n",
            "mean reward:111.710\n",
            "mean reward:110.170\n",
            "mean reward:114.600\n",
            "mean reward:114.080\n",
            "mean reward:111.520\n",
            "mean reward:102.730\n",
            "mean reward:116.170\n",
            "mean reward:117.220\n",
            "mean reward:66.630\n",
            "mean reward:90.130\n",
            "mean reward:98.560\n",
            "mean reward:100.530\n",
            "mean reward:106.780\n",
            "mean reward:104.640\n",
            "mean reward:118.610\n",
            "mean reward:117.790\n",
            "mean reward:127.270\n",
            "mean reward:122.690\n",
            "mean reward:139.810\n",
            "mean reward:150.470\n",
            "mean reward:116.280\n",
            "mean reward:108.530\n",
            "mean reward:127.090\n",
            "mean reward:127.010\n",
            "mean reward:131.040\n",
            "mean reward:636.740\n",
            "mean reward:1000.000\n",
            "You Win!\n"
          ]
        }
      ],
      "source": [
        "for i in range(500):\n",
        "    rewards = [train_on_session(*generate_session(env), entropy_coef=1e-3) for _ in range(100)]  # generate new sessions\n",
        "\n",
        "    print(\"mean reward:%.3f\" % (np.mean(rewards)))\n",
        "\n",
        "    if np.mean(rewards) > 800:\n",
        "        print(\"You Win!\")  # but you can train even further\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg__sQeti2TF"
      },
      "source": [
        "### Watch the video of your results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "tFWK1k90LorI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium.utils.save_video import save_video\n",
        "\n",
        "env_for_video = gym.make(\"CartPole-v1\", render_mode=\"rgb_array_list\")\n",
        "n_actions = env_for_video.action_space.n\n",
        "\n",
        "episode_index = 0\n",
        "step_starting_index = 0\n",
        "\n",
        "obs, info = env_for_video.reset()\n",
        "\n",
        "for step_index in range(800):\n",
        "    probs = predict_probs(np.array([obs]))[0]\n",
        "    action = np.random.choice(n_actions, p=probs)\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env_for_video.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    if done or step_index == 799:\n",
        "        # env_for_video.render() now returns the LIST of frames accumulated so far\n",
        "        frames = env_for_video.render()\n",
        "        os.makedirs(\"videos\", exist_ok=True)\n",
        "        save_video(\n",
        "            frames, \"videos\",\n",
        "            fps=env_for_video.metadata.get(\"render_fps\", 30),\n",
        "            step_starting_index=step_starting_index,\n",
        "            episode_index=episode_index,\n",
        "        )\n",
        "        episode_index += 1\n",
        "        step_starting_index = step_index + 1\n",
        "        obs, info = env_for_video.reset()\n",
        "\n",
        "env_for_video.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p2KVphMLorI"
      },
      "source": [
        "Congratulations! Finally, copy the `predict_probs`, `get_cumulative_rewards` and `get_loss` to the template and submit them to the Contest.\n",
        "\n",
        "Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T135ih05LorI"
      },
      "source": [
        "## Bonus part (no points, just for the interested ones)\n",
        "\n",
        "Try solving the `Acrobot-v1` environment. It is more complex than regular `CartPole-v1`, so the default Policy Gradient (REINFORCE) algorithm might not work. Maybe the baseline idea could help...\n",
        "\n",
        "![Acrobot](https://gymnasium.farama.org/_images/acrobot.gif)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "2J96g2lnLorI",
        "outputId": "9f0126a3-6630-43c7-f8ff-2b6f0f0639db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78ca792ef6e0>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "env = gym.make(\"Acrobot-v1\", render_mode=\"rgb_array\")\n",
        "\n",
        "\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "\n",
        "plt.imshow(env.render())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "pDNY5YrlLorI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3_main",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}