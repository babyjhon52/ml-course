{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "## Переобучение нейронных сетей и борьба с ним\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/girafe_ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQm5qJTnemw2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o9jqgb7qemw2"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "def args_and_kwargs(*args, **kwargs):\n",
        "    return args, kwargs\n",
        "\n",
        "def parse_pytorch_model(model_str):\n",
        "    def parse_layer(layer_str):\n",
        "        layer_name, params = layer_str.split(\"(\", 1)\n",
        "        layer_info = {\"type\": layer_name.strip()}\n",
        "        params_template = layer_str.replace(layer_name, \"args_and_kwargs\")\n",
        "\n",
        "        param_dict = {}\n",
        "        if len(params):\n",
        "            args, kwargs = eval(params_template)\n",
        "            if len(args) or len(kwargs):\n",
        "                param_dict[\"args\"] = args\n",
        "                for name, value in kwargs.items():\n",
        "                    param_dict[name] = value\n",
        "        layer_info[\"parameters\"] = param_dict\n",
        "        return layer_info\n",
        "\n",
        "    model_dict = {}\n",
        "    lines = model_str.splitlines()\n",
        "    model_name = lines[0].strip(\"()\")\n",
        "    model_dict[\"model_name\"] = model_name\n",
        "    model_dict[\"layers\"] = []\n",
        "\n",
        "    layer_regex = re.compile(r\"\\((\\d+)\\): (.+)\")\n",
        "    for line in lines[1:]:\n",
        "        line = line.strip()\n",
        "        match = layer_regex.match(line)\n",
        "        if match:\n",
        "            index, layer = match.groups()\n",
        "            model_dict[\"layers\"].append({\"index\": int(index), \"layer\": parse_layer(layer)})\n",
        "    return model_dict\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3zfHwLB7emw3"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMUCdq46emw3"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L7mt1mWaemw3",
        "outputId": "0690a32d-9dcc-4847-f38f-c5c7222e7716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-15 10:22:01--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-06-15 10:22:02--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-06-15 10:22:03 (90.9 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hpwYCJOHemw3"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Задача №1 (уже решённая): Создание и обучение модели (Separation)\n",
        "Вы уже решали эту задачу ранее, так что сейчас просто воспроизведите своё решение. Оно понадобится вам в дальнейших шагах.\n",
        "__Ваша первая задача всё та же: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BSTOPYQkemw3"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "aYcL28OsgSq8",
        "outputId": "51f50253-9d6c-486a-cc3f-b1a39096bca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 13.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 199kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.75MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 24.1MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 8')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3) # (batch, 3, 26, 26)\n",
        "        self.conv2 = nn.Conv2d(3, 4, 3) # (batch, 3, 24, 24)\n",
        "        self.conv3 = nn.Conv2d(4, 8, 3) # (batch, 3, 22, 22)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(8*22*22, 64)\n",
        "        self.linear2 = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "model_task_1 = Model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "GpmjndAwPH-a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "c06a6254-a55c-4bef-ab13-d6fdbc60b671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear1): Linear(in_features=3872, out_features=64, bias=True)\n",
              "  (linear2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "51de5c05-b20c-45b6-ad28-3f3a01e0b550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "58c54d80-6912-4ef2-b113-22148cf86e37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.2408\n",
            "Epoch 2, Loss: 0.2929\n",
            "Epoch 3, Loss: 0.3787\n",
            "Epoch 4, Loss: 0.3187\n",
            "Epoch 5, Loss: 0.2122\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model_task_1.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "losses = []\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for train_batch in train_data_loader:\n",
        "        images, labels = train_batch[0].to(device), train_batch[1].to(device)\n",
        "        model_task_1.zero_grad()\n",
        "\n",
        "        output = model_task_1(images)\n",
        "\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()                                # шаг оптимизации\n",
        "        losses.append(loss.item())                      # сохраняем значение ошибки\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "7d226cc5-a2ca-4868-8bb7-9ab6f20b024e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.92062\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "fa71e36c-da15-4712-9794-4ee20c3a4ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8952\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuDB7n_aemw5"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "koFyhiCFemw5",
        "outputId": "651e7bac-dbed-4110-c828-e8cf34538b5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_task_1.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "    \"model_task_1\": parse_pytorch_model(str(model_task_1)),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zZGLUbxemw5"
      },
      "source": [
        "### Задача №2: Переобучение (Initiation)\n",
        "Продолжим работу с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Теперь ваша задача продемонстрировать переобучение модели на обучающей выборке. Достаточно показать, что точность классификации (не только функция потерь!) на тестовой выборке значительно отстает от обучающей.\n",
        "\n",
        "Обращаем ваше внимание, в задаче №3 вам придется починить данную модель (минимизировать эффект переобучения) с помощью механизмов регуляризации, поэтому не переусердствуйте!\n",
        "\n",
        "__Ваша вторая задача: реализовать используя пайплан обучения модели продемонстрировать переобучения модели на обучающей выборке.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVDj8Eo9emw5"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_2` для хранение модели во второй задаче.\n",
        "\n",
        "Не используйте `Dropout` и `BatchNorm` в этой задаче"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4vucj4bgemw5"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model_task_2 = None\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1oYePtyvemw5"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6GFGcF-emw5"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2Xwec1_pemw5"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_2 = []\n",
        "for element in parse_pytorch_model(str(model_task_1)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    assert \"dropout\" not in layer_name.lower(), \"Do not use Dropout in Task 2!\"\n",
        "    assert \"batchnorm\" not in layer_name.lower(), \"Do not use BatchNorm in Task 2!\"\n",
        "    layers_task_2.append(layer_name)\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mPaegyHemw5"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UHHwQd4kemw5",
        "outputId": "21a58586-572a-4bfc-fd0f-78cc2e929a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.92062\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_2 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L6MpcAcAemw5",
        "outputId": "a4556343-f599-424b-e5cf-277a6d4b2028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8952\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_2 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_2:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xFvjYgRemw5"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AL85VnJCemw5",
        "outputId": "45fd387d-9bd9-45a6-90a5-1543eca660ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Test accuracy should be at least 0.04 lower that train.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-695637110>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc_task_2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.88\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train accuracy must be higher than 0.88\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_acc_task_2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_acc_task_2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.04\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ), \"Test accuracy should be at least 0.04 lower that train.\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Test accuracy should be at least 0.04 lower that train."
          ]
        }
      ],
      "source": [
        "assert train_acc_task_2 >= test_acc_task_2, \"Train accuracy must be higher than task accuracy\"\n",
        "assert train_acc_task_2 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert (\n",
        "    train_acc_task_2 - test_acc_task_2 >= 0.04\n",
        "), \"Test accuracy should be at least 0.04 lower that train.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XQZeya2emw6"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_2`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задачи №1. Если их там нет, загрузите их из сохраненного файла в переменную перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BGYBqjgRemw6",
        "outputId": "55ef3e75-5bd2-4af7-d6fc-2799644b0ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved to `submission_dict_tasks_1_and_2.json`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_2\": get_predictions(\n",
        "            model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_2\": get_predictions(\n",
        "            model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_2\": parse_pytorch_model(str(model_task_1)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_tasks_1_and_2.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_tasks_1_and_2.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Koynej5zemw6"
      },
      "source": [
        "### Задача №3: Исправление модели (Return)\n",
        "Все так же работаем с [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Наконец, ваша задача исправить ~~ошибки прошлого~~ переобучение модели, построенной в задаче 2. Достаточно добиться расхождения между точностью классификации на обучающей и тестовой выборках не превышающего 0.015 (т.е. полутора процентов).\n",
        "\n",
        "Обращаем ваше внимание, архитектура модели в задаче №3 не должна существенно отличаться от задачи №2! Вы можете использовать Batchnorm, Dropout, уменьшить размерность промежуточных представлений, обратиться к аугментации данных, но вы не можете использовать меньшее количество слоёв.\n",
        "\n",
        "__Ваша третья и финальная задача: исправить модель и/или процесс обучения, дабы справиться с переобучением.__\n",
        "\n",
        "Код для обучения модели вы можете переиспользовать. Далее присутствует лишь несколько тестов, которые помогут вам проверить свое решение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVrsgtLOemw6"
      },
      "source": [
        "Обращаем внимание, вам необходимо использовать переменную `model_task_3` для хранение модели во второй задаче.\n",
        "\n",
        "Также код ниже будет обращаться к переменной `layers_task_2`, инициализируйте её, если она не определена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gwIsweLXemw6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert (\n",
        "    layers_task_2 is not None\n",
        "), \"Initializa layers_task_2 vairable which contains list of layers in task 2 model\"\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "heiCwe47emw6",
        "outputId": "a32441c8-071b-4134-e114-4c2acf3e4153",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model_Overfit(\n",
              "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batch2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (batch3): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear1): Linear(in_features=3872, out_features=64, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (linear2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model_Overfit(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 3, 3) # (batch, 3, 26, 26)\n",
        "        self.batch1 = nn.BatchNorm2d(3)\n",
        "        self.conv2 = nn.Conv2d(3, 4, 3) # (batch, 4, 24, 24)\n",
        "        self.batch2 = nn.BatchNorm2d(4)\n",
        "        self.conv3 = nn.Conv2d(4, 8, 3) # (batch, 8, 22, 22)\n",
        "        self.batch3 = nn.BatchNorm2d(8)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(8*22*22, 64)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.linear2 = nn.Linear(64, 10)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.batch1(self.conv1(x)))\n",
        "        x = F.relu(self.batch2(self.conv2(x)))\n",
        "        x = F.relu(self.batch3(self.conv3(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(F.relu(self.linear1(x)))\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model_task_3 = Model_Overfit()\n",
        "model_task_3.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ICdl_GLNemw6",
        "outputId": "af52ef4a-640a-4b03-a6f2-977fe03e57bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.7720\n",
            "Epoch 2, Loss: 0.5997\n",
            "Epoch 3, Loss: 0.2669\n",
            "Epoch 4, Loss: 0.2572\n",
            "Epoch 5, Loss: 0.2892\n",
            "Epoch 6, Loss: 0.1626\n",
            "Epoch 7, Loss: 0.3332\n",
            "Epoch 8, Loss: 0.2138\n",
            "Epoch 9, Loss: 0.1669\n",
            "Epoch 10, Loss: 0.3189\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = torch.optim.Adam(model_task_3.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "losses = []\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for train_batch in train_data_loader:\n",
        "        images, labels = train_batch[0].to(device), train_batch[1].to(device)\n",
        "        model_task_3.zero_grad()\n",
        "\n",
        "        output = model_task_3(images)\n",
        "\n",
        "        loss = loss_fn(output, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()                                # шаг оптимизации\n",
        "        losses.append(loss.item())                      # сохраняем значение ошибки\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhgeyq-wemw6"
      },
      "source": [
        "Проверка архитектуры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "b4yDDfYremw6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "layers_task_3 = []\n",
        "for element in parse_pytorch_model(str(model_task_3)).get(\"layers\", []):\n",
        "    layer_name = element[\"layer\"][\"type\"]\n",
        "    layers_task_3.append(layer_name)\n",
        "\n",
        "\n",
        "idx = 0\n",
        "for model_3_layer in layers_task_3:\n",
        "    model_2_layer = layers_task_2[idx]\n",
        "    if \"dropout\" not in model_3_layer.lower() and \"batchnorm\" not in model_3_layer.lower():\n",
        "        assert (\n",
        "            model_3_layer == model_2_layer\n",
        "        ), \"Models in tasks 2 and 3 must share the architecture except for Dropout and BatchNorm!\"\n",
        "        idx += 1\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Пробуем юзать что-то другое"
      ],
      "metadata": {
        "id": "C_j1Kq8HXwfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier"
      ],
      "metadata": {
        "id": "OVLunX-iXy6k"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "PrZWDKXRISe-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_list, y_list = [], []\n",
        "\n",
        "X_test, y_test = [], []\n",
        "\n",
        "for images, labels in train_data_loader:\n",
        "    X_list.append(images.view(images.size(0), -1).cpu())  # (batch, C*H*W)\n",
        "    y_list.append(labels.cpu())\n",
        "\n",
        "X_all = torch.cat(X_list, dim=0).numpy()  # (N, C*H*W)\n",
        "y_all = torch.cat(y_list, dim=0).numpy()\n",
        "\n",
        "pca = PCA(n_components=50)  # или другое число компонент\n",
        "X_pca = pca.fit_transform(X_all)\n",
        "\n",
        "for images, labels in test_data_loader:\n",
        "    X_test.append(images.view(images.size(0), -1).cpu())  # (batch, C*H*W)\n",
        "    y_test.append(labels.cpu())\n",
        "\n",
        "X_all_test = torch.cat(X_test, dim=0).numpy()  # (N, C*H*W)\n",
        "y_all_test = torch.cat(y_test, dim=0).numpy()\n",
        "\n",
        "X_all_pca = pca.transform(X_all_test)"
      ],
      "metadata": {
        "id": "Esmtcu1wJiAh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "model = CatBoostClassifier()\n",
        "\n",
        "model.fit(X_pca, y_all)\n",
        "\n",
        "print(accuracy_score(y_all_test, model.predict(X_all_pca)))\n"
      ],
      "metadata": {
        "id": "iMZibVOZJn6V",
        "outputId": "5d8140e4-a4e1-40a8-c536-90a2ad9652b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.097501\n",
            "0:\tlearn: 1.9697517\ttotal: 852ms\tremaining: 14m 11s\n",
            "1:\tlearn: 1.7757546\ttotal: 1.89s\tremaining: 15m 42s\n",
            "2:\tlearn: 1.6243603\ttotal: 2.84s\tremaining: 15m 43s\n",
            "3:\tlearn: 1.5055260\ttotal: 3.32s\tremaining: 13m 47s\n",
            "4:\tlearn: 1.4172260\ttotal: 3.68s\tremaining: 12m 11s\n",
            "5:\tlearn: 1.3314941\ttotal: 4.05s\tremaining: 11m 10s\n",
            "6:\tlearn: 1.2612070\ttotal: 4.4s\tremaining: 10m 24s\n",
            "7:\tlearn: 1.2031500\ttotal: 4.77s\tremaining: 9m 51s\n",
            "8:\tlearn: 1.1524943\ttotal: 5.14s\tremaining: 9m 25s\n",
            "9:\tlearn: 1.1051595\ttotal: 5.49s\tremaining: 9m 3s\n",
            "10:\tlearn: 1.0632735\ttotal: 5.85s\tremaining: 8m 45s\n",
            "11:\tlearn: 1.0256026\ttotal: 6.22s\tremaining: 8m 31s\n",
            "12:\tlearn: 0.9924321\ttotal: 6.57s\tremaining: 8m 18s\n",
            "13:\tlearn: 0.9655202\ttotal: 6.93s\tremaining: 8m 8s\n",
            "14:\tlearn: 0.9380733\ttotal: 7.3s\tremaining: 7m 59s\n",
            "15:\tlearn: 0.9124573\ttotal: 7.66s\tremaining: 7m 50s\n",
            "16:\tlearn: 0.8859600\ttotal: 8.01s\tremaining: 7m 43s\n",
            "17:\tlearn: 0.8640109\ttotal: 8.38s\tremaining: 7m 37s\n",
            "18:\tlearn: 0.8434607\ttotal: 8.74s\tremaining: 7m 31s\n",
            "19:\tlearn: 0.8280767\ttotal: 9.09s\tremaining: 7m 25s\n",
            "20:\tlearn: 0.8102101\ttotal: 9.46s\tremaining: 7m 20s\n",
            "21:\tlearn: 0.7950009\ttotal: 9.81s\tremaining: 7m 16s\n",
            "22:\tlearn: 0.7806655\ttotal: 10.2s\tremaining: 7m 11s\n",
            "23:\tlearn: 0.7683879\ttotal: 10.5s\tremaining: 7m 8s\n",
            "24:\tlearn: 0.7545679\ttotal: 10.9s\tremaining: 7m 4s\n",
            "25:\tlearn: 0.7408266\ttotal: 11.3s\tremaining: 7m 1s\n",
            "26:\tlearn: 0.7289283\ttotal: 11.6s\tremaining: 6m 58s\n",
            "27:\tlearn: 0.7165570\ttotal: 12s\tremaining: 6m 56s\n",
            "28:\tlearn: 0.7057410\ttotal: 12.3s\tremaining: 6m 53s\n",
            "29:\tlearn: 0.6967082\ttotal: 12.7s\tremaining: 6m 51s\n",
            "30:\tlearn: 0.6864068\ttotal: 13.1s\tremaining: 6m 48s\n",
            "31:\tlearn: 0.6771137\ttotal: 13.6s\tremaining: 6m 51s\n",
            "32:\tlearn: 0.6672214\ttotal: 14.2s\tremaining: 6m 55s\n",
            "33:\tlearn: 0.6579393\ttotal: 14.9s\tremaining: 7m 2s\n",
            "34:\tlearn: 0.6500987\ttotal: 15.4s\tremaining: 7m 4s\n",
            "35:\tlearn: 0.6430147\ttotal: 15.9s\tremaining: 7m 6s\n",
            "36:\tlearn: 0.6358837\ttotal: 16.3s\tremaining: 7m 3s\n",
            "37:\tlearn: 0.6283147\ttotal: 16.6s\tremaining: 7m 1s\n",
            "38:\tlearn: 0.6207234\ttotal: 17s\tremaining: 6m 58s\n",
            "39:\tlearn: 0.6145945\ttotal: 17.4s\tremaining: 6m 56s\n",
            "40:\tlearn: 0.6074468\ttotal: 17.7s\tremaining: 6m 55s\n",
            "41:\tlearn: 0.6009087\ttotal: 18.1s\tremaining: 6m 52s\n",
            "42:\tlearn: 0.5950117\ttotal: 18.5s\tremaining: 6m 50s\n",
            "43:\tlearn: 0.5894950\ttotal: 18.8s\tremaining: 6m 49s\n",
            "44:\tlearn: 0.5846666\ttotal: 19.2s\tremaining: 6m 47s\n",
            "45:\tlearn: 0.5795873\ttotal: 19.6s\tremaining: 6m 45s\n",
            "46:\tlearn: 0.5746850\ttotal: 19.9s\tremaining: 6m 44s\n",
            "47:\tlearn: 0.5683167\ttotal: 20.3s\tremaining: 6m 42s\n",
            "48:\tlearn: 0.5632313\ttotal: 20.7s\tremaining: 6m 40s\n",
            "49:\tlearn: 0.5586956\ttotal: 21s\tremaining: 6m 39s\n",
            "50:\tlearn: 0.5552386\ttotal: 21.4s\tremaining: 6m 37s\n",
            "51:\tlearn: 0.5511319\ttotal: 21.7s\tremaining: 6m 36s\n",
            "52:\tlearn: 0.5471066\ttotal: 22.1s\tremaining: 6m 35s\n",
            "53:\tlearn: 0.5435121\ttotal: 22.5s\tremaining: 6m 33s\n",
            "54:\tlearn: 0.5398320\ttotal: 22.8s\tremaining: 6m 32s\n",
            "55:\tlearn: 0.5361783\ttotal: 23.5s\tremaining: 6m 35s\n",
            "56:\tlearn: 0.5330079\ttotal: 24.2s\tremaining: 6m 40s\n",
            "57:\tlearn: 0.5295406\ttotal: 24.5s\tremaining: 6m 38s\n",
            "58:\tlearn: 0.5265303\ttotal: 24.9s\tremaining: 6m 37s\n",
            "59:\tlearn: 0.5236469\ttotal: 25.3s\tremaining: 6m 35s\n",
            "60:\tlearn: 0.5203612\ttotal: 25.6s\tremaining: 6m 34s\n",
            "61:\tlearn: 0.5172933\ttotal: 26.1s\tremaining: 6m 34s\n",
            "62:\tlearn: 0.5138039\ttotal: 26.7s\tremaining: 6m 37s\n",
            "63:\tlearn: 0.5105344\ttotal: 27.3s\tremaining: 6m 39s\n",
            "64:\tlearn: 0.5070076\ttotal: 27.9s\tremaining: 6m 41s\n",
            "65:\tlearn: 0.5041878\ttotal: 28.5s\tremaining: 6m 43s\n",
            "66:\tlearn: 0.5014319\ttotal: 28.8s\tremaining: 6m 41s\n",
            "67:\tlearn: 0.4984031\ttotal: 29.2s\tremaining: 6m 40s\n",
            "68:\tlearn: 0.4955790\ttotal: 29.6s\tremaining: 6m 39s\n",
            "69:\tlearn: 0.4933674\ttotal: 29.9s\tremaining: 6m 37s\n",
            "70:\tlearn: 0.4907977\ttotal: 30.3s\tremaining: 6m 36s\n",
            "71:\tlearn: 0.4883372\ttotal: 30.7s\tremaining: 6m 35s\n",
            "72:\tlearn: 0.4856579\ttotal: 31s\tremaining: 6m 34s\n",
            "73:\tlearn: 0.4830501\ttotal: 31.4s\tremaining: 6m 32s\n",
            "74:\tlearn: 0.4806477\ttotal: 31.8s\tremaining: 6m 31s\n",
            "75:\tlearn: 0.4792574\ttotal: 32.1s\tremaining: 6m 30s\n",
            "76:\tlearn: 0.4764760\ttotal: 32.5s\tremaining: 6m 29s\n",
            "77:\tlearn: 0.4746993\ttotal: 32.9s\tremaining: 6m 28s\n",
            "78:\tlearn: 0.4727923\ttotal: 33.2s\tremaining: 6m 27s\n",
            "79:\tlearn: 0.4706863\ttotal: 33.6s\tremaining: 6m 26s\n",
            "80:\tlearn: 0.4683882\ttotal: 34s\tremaining: 6m 25s\n",
            "81:\tlearn: 0.4668601\ttotal: 34.3s\tremaining: 6m 24s\n",
            "82:\tlearn: 0.4649365\ttotal: 34.7s\tremaining: 6m 23s\n",
            "83:\tlearn: 0.4631129\ttotal: 35.1s\tremaining: 6m 22s\n",
            "84:\tlearn: 0.4611527\ttotal: 35.4s\tremaining: 6m 21s\n",
            "85:\tlearn: 0.4589600\ttotal: 35.8s\tremaining: 6m 20s\n",
            "86:\tlearn: 0.4572000\ttotal: 36.2s\tremaining: 6m 19s\n",
            "87:\tlearn: 0.4554749\ttotal: 36.5s\tremaining: 6m 18s\n",
            "88:\tlearn: 0.4540247\ttotal: 36.9s\tremaining: 6m 17s\n",
            "89:\tlearn: 0.4520798\ttotal: 37.2s\tremaining: 6m 16s\n",
            "90:\tlearn: 0.4503113\ttotal: 37.6s\tremaining: 6m 15s\n",
            "91:\tlearn: 0.4485982\ttotal: 38s\tremaining: 6m 14s\n",
            "92:\tlearn: 0.4467225\ttotal: 38.3s\tremaining: 6m 13s\n",
            "93:\tlearn: 0.4448312\ttotal: 38.9s\tremaining: 6m 14s\n",
            "94:\tlearn: 0.4433271\ttotal: 39.5s\tremaining: 6m 15s\n",
            "95:\tlearn: 0.4416463\ttotal: 40.1s\tremaining: 6m 17s\n",
            "96:\tlearn: 0.4404715\ttotal: 40.7s\tremaining: 6m 19s\n",
            "97:\tlearn: 0.4390342\ttotal: 41.2s\tremaining: 6m 19s\n",
            "98:\tlearn: 0.4373913\ttotal: 41.6s\tremaining: 6m 18s\n",
            "99:\tlearn: 0.4356461\ttotal: 42s\tremaining: 6m 17s\n",
            "100:\tlearn: 0.4340582\ttotal: 42.3s\tremaining: 6m 16s\n",
            "101:\tlearn: 0.4329441\ttotal: 42.7s\tremaining: 6m 15s\n",
            "102:\tlearn: 0.4311601\ttotal: 43.1s\tremaining: 6m 14s\n",
            "103:\tlearn: 0.4295682\ttotal: 43.4s\tremaining: 6m 14s\n",
            "104:\tlearn: 0.4279426\ttotal: 43.8s\tremaining: 6m 13s\n",
            "105:\tlearn: 0.4267125\ttotal: 44.2s\tremaining: 6m 12s\n",
            "106:\tlearn: 0.4249877\ttotal: 44.5s\tremaining: 6m 11s\n",
            "107:\tlearn: 0.4237879\ttotal: 44.9s\tremaining: 6m 10s\n",
            "108:\tlearn: 0.4230028\ttotal: 45.2s\tremaining: 6m 9s\n",
            "109:\tlearn: 0.4216883\ttotal: 45.6s\tremaining: 6m 8s\n",
            "110:\tlearn: 0.4206575\ttotal: 46s\tremaining: 6m 8s\n",
            "111:\tlearn: 0.4190400\ttotal: 46.3s\tremaining: 6m 7s\n",
            "112:\tlearn: 0.4178562\ttotal: 46.7s\tremaining: 6m 6s\n",
            "113:\tlearn: 0.4168828\ttotal: 47.1s\tremaining: 6m 5s\n",
            "114:\tlearn: 0.4160065\ttotal: 47.4s\tremaining: 6m 4s\n",
            "115:\tlearn: 0.4151237\ttotal: 47.8s\tremaining: 6m 3s\n",
            "116:\tlearn: 0.4140840\ttotal: 48.1s\tremaining: 6m 3s\n",
            "117:\tlearn: 0.4129324\ttotal: 48.5s\tremaining: 6m 2s\n",
            "118:\tlearn: 0.4118822\ttotal: 48.9s\tremaining: 6m 1s\n",
            "119:\tlearn: 0.4105311\ttotal: 49.2s\tremaining: 6m 1s\n",
            "120:\tlearn: 0.4095152\ttotal: 49.6s\tremaining: 6m\n",
            "121:\tlearn: 0.4084018\ttotal: 49.9s\tremaining: 5m 59s\n",
            "122:\tlearn: 0.4073610\ttotal: 50.3s\tremaining: 5m 58s\n",
            "123:\tlearn: 0.4063745\ttotal: 50.7s\tremaining: 5m 58s\n",
            "124:\tlearn: 0.4052818\ttotal: 51.1s\tremaining: 5m 57s\n",
            "125:\tlearn: 0.4042098\ttotal: 51.6s\tremaining: 5m 58s\n",
            "126:\tlearn: 0.4034261\ttotal: 52.3s\tremaining: 5m 59s\n",
            "127:\tlearn: 0.4026139\ttotal: 52.9s\tremaining: 6m\n",
            "128:\tlearn: 0.4017715\ttotal: 53.5s\tremaining: 6m 1s\n",
            "129:\tlearn: 0.4004577\ttotal: 53.9s\tremaining: 6m\n",
            "130:\tlearn: 0.3993465\ttotal: 54.3s\tremaining: 5m 59s\n",
            "131:\tlearn: 0.3984039\ttotal: 54.6s\tremaining: 5m 59s\n",
            "132:\tlearn: 0.3976932\ttotal: 55s\tremaining: 5m 58s\n",
            "133:\tlearn: 0.3966697\ttotal: 55.3s\tremaining: 5m 57s\n",
            "134:\tlearn: 0.3955937\ttotal: 55.7s\tremaining: 5m 57s\n",
            "135:\tlearn: 0.3948790\ttotal: 56.1s\tremaining: 5m 56s\n",
            "136:\tlearn: 0.3938978\ttotal: 56.4s\tremaining: 5m 55s\n",
            "137:\tlearn: 0.3926819\ttotal: 56.8s\tremaining: 5m 54s\n",
            "138:\tlearn: 0.3919940\ttotal: 57.2s\tremaining: 5m 54s\n",
            "139:\tlearn: 0.3910439\ttotal: 57.5s\tremaining: 5m 53s\n",
            "140:\tlearn: 0.3899806\ttotal: 57.9s\tremaining: 5m 52s\n",
            "141:\tlearn: 0.3891609\ttotal: 58.2s\tremaining: 5m 51s\n",
            "142:\tlearn: 0.3881337\ttotal: 58.6s\tremaining: 5m 51s\n",
            "143:\tlearn: 0.3872174\ttotal: 59s\tremaining: 5m 50s\n",
            "144:\tlearn: 0.3863546\ttotal: 59.3s\tremaining: 5m 49s\n",
            "145:\tlearn: 0.3851143\ttotal: 59.7s\tremaining: 5m 49s\n",
            "146:\tlearn: 0.3840682\ttotal: 1m\tremaining: 5m 48s\n",
            "147:\tlearn: 0.3833405\ttotal: 1m\tremaining: 5m 47s\n",
            "148:\tlearn: 0.3826779\ttotal: 1m\tremaining: 5m 47s\n",
            "149:\tlearn: 0.3817909\ttotal: 1m 1s\tremaining: 5m 46s\n",
            "150:\tlearn: 0.3808255\ttotal: 1m 1s\tremaining: 5m 45s\n",
            "151:\tlearn: 0.3801302\ttotal: 1m 1s\tremaining: 5m 45s\n",
            "152:\tlearn: 0.3794816\ttotal: 1m 2s\tremaining: 5m 44s\n",
            "153:\tlearn: 0.3787590\ttotal: 1m 2s\tremaining: 5m 44s\n",
            "154:\tlearn: 0.3779017\ttotal: 1m 3s\tremaining: 5m 43s\n",
            "155:\tlearn: 0.3770638\ttotal: 1m 3s\tremaining: 5m 42s\n",
            "156:\tlearn: 0.3763302\ttotal: 1m 3s\tremaining: 5m 42s\n",
            "157:\tlearn: 0.3755520\ttotal: 1m 4s\tremaining: 5m 42s\n",
            "158:\tlearn: 0.3752188\ttotal: 1m 4s\tremaining: 5m 43s\n",
            "159:\tlearn: 0.3746405\ttotal: 1m 5s\tremaining: 5m 44s\n",
            "160:\tlearn: 0.3737526\ttotal: 1m 6s\tremaining: 5m 44s\n",
            "161:\tlearn: 0.3727520\ttotal: 1m 6s\tremaining: 5m 44s\n",
            "162:\tlearn: 0.3720723\ttotal: 1m 6s\tremaining: 5m 43s\n",
            "163:\tlearn: 0.3712052\ttotal: 1m 7s\tremaining: 5m 42s\n",
            "164:\tlearn: 0.3705162\ttotal: 1m 7s\tremaining: 5m 42s\n",
            "165:\tlearn: 0.3699232\ttotal: 1m 8s\tremaining: 5m 41s\n",
            "166:\tlearn: 0.3693123\ttotal: 1m 8s\tremaining: 5m 40s\n",
            "167:\tlearn: 0.3689197\ttotal: 1m 8s\tremaining: 5m 40s\n",
            "168:\tlearn: 0.3681867\ttotal: 1m 9s\tremaining: 5m 39s\n",
            "169:\tlearn: 0.3671740\ttotal: 1m 9s\tremaining: 5m 39s\n",
            "170:\tlearn: 0.3665229\ttotal: 1m 9s\tremaining: 5m 38s\n",
            "171:\tlearn: 0.3657376\ttotal: 1m 10s\tremaining: 5m 37s\n",
            "172:\tlearn: 0.3652005\ttotal: 1m 10s\tremaining: 5m 37s\n",
            "173:\tlearn: 0.3648768\ttotal: 1m 10s\tremaining: 5m 36s\n",
            "174:\tlearn: 0.3645319\ttotal: 1m 11s\tremaining: 5m 35s\n",
            "175:\tlearn: 0.3641715\ttotal: 1m 11s\tremaining: 5m 35s\n",
            "176:\tlearn: 0.3637005\ttotal: 1m 11s\tremaining: 5m 34s\n",
            "177:\tlearn: 0.3629495\ttotal: 1m 12s\tremaining: 5m 34s\n",
            "178:\tlearn: 0.3624318\ttotal: 1m 12s\tremaining: 5m 33s\n",
            "179:\tlearn: 0.3620443\ttotal: 1m 13s\tremaining: 5m 32s\n",
            "180:\tlearn: 0.3614175\ttotal: 1m 13s\tremaining: 5m 32s\n",
            "181:\tlearn: 0.3607466\ttotal: 1m 13s\tremaining: 5m 31s\n",
            "182:\tlearn: 0.3602250\ttotal: 1m 14s\tremaining: 5m 30s\n",
            "183:\tlearn: 0.3600309\ttotal: 1m 14s\tremaining: 5m 30s\n",
            "184:\tlearn: 0.3594195\ttotal: 1m 14s\tremaining: 5m 29s\n",
            "185:\tlearn: 0.3588789\ttotal: 1m 15s\tremaining: 5m 28s\n",
            "186:\tlearn: 0.3580139\ttotal: 1m 15s\tremaining: 5m 28s\n",
            "187:\tlearn: 0.3576293\ttotal: 1m 15s\tremaining: 5m 27s\n",
            "188:\tlearn: 0.3569527\ttotal: 1m 16s\tremaining: 5m 27s\n",
            "189:\tlearn: 0.3566588\ttotal: 1m 16s\tremaining: 5m 27s\n",
            "190:\tlearn: 0.3559159\ttotal: 1m 17s\tremaining: 5m 28s\n",
            "191:\tlearn: 0.3551756\ttotal: 1m 18s\tremaining: 5m 28s\n",
            "192:\tlearn: 0.3545421\ttotal: 1m 18s\tremaining: 5m 29s\n",
            "193:\tlearn: 0.3539418\ttotal: 1m 19s\tremaining: 5m 28s\n",
            "194:\tlearn: 0.3533658\ttotal: 1m 19s\tremaining: 5m 28s\n",
            "195:\tlearn: 0.3526195\ttotal: 1m 19s\tremaining: 5m 27s\n",
            "196:\tlearn: 0.3523869\ttotal: 1m 20s\tremaining: 5m 26s\n",
            "197:\tlearn: 0.3520428\ttotal: 1m 20s\tremaining: 5m 26s\n",
            "198:\tlearn: 0.3514148\ttotal: 1m 20s\tremaining: 5m 25s\n",
            "199:\tlearn: 0.3510224\ttotal: 1m 21s\tremaining: 5m 25s\n",
            "200:\tlearn: 0.3503532\ttotal: 1m 21s\tremaining: 5m 24s\n",
            "201:\tlearn: 0.3497263\ttotal: 1m 22s\tremaining: 5m 23s\n",
            "202:\tlearn: 0.3494132\ttotal: 1m 22s\tremaining: 5m 23s\n",
            "203:\tlearn: 0.3488022\ttotal: 1m 22s\tremaining: 5m 22s\n",
            "204:\tlearn: 0.3482873\ttotal: 1m 23s\tremaining: 5m 22s\n",
            "205:\tlearn: 0.3476893\ttotal: 1m 23s\tremaining: 5m 21s\n",
            "206:\tlearn: 0.3472729\ttotal: 1m 23s\tremaining: 5m 21s\n",
            "207:\tlearn: 0.3468078\ttotal: 1m 24s\tremaining: 5m 20s\n",
            "208:\tlearn: 0.3463291\ttotal: 1m 24s\tremaining: 5m 19s\n",
            "209:\tlearn: 0.3458648\ttotal: 1m 24s\tremaining: 5m 19s\n",
            "210:\tlearn: 0.3453814\ttotal: 1m 25s\tremaining: 5m 18s\n",
            "211:\tlearn: 0.3448090\ttotal: 1m 25s\tremaining: 5m 18s\n",
            "212:\tlearn: 0.3445514\ttotal: 1m 25s\tremaining: 5m 17s\n",
            "213:\tlearn: 0.3440908\ttotal: 1m 26s\tremaining: 5m 16s\n",
            "214:\tlearn: 0.3436254\ttotal: 1m 26s\tremaining: 5m 16s\n",
            "215:\tlearn: 0.3432137\ttotal: 1m 27s\tremaining: 5m 15s\n",
            "216:\tlearn: 0.3426825\ttotal: 1m 27s\tremaining: 5m 15s\n",
            "217:\tlearn: 0.3420574\ttotal: 1m 27s\tremaining: 5m 14s\n",
            "218:\tlearn: 0.3418282\ttotal: 1m 28s\tremaining: 5m 14s\n",
            "219:\tlearn: 0.3414560\ttotal: 1m 28s\tremaining: 5m 13s\n",
            "220:\tlearn: 0.3411491\ttotal: 1m 28s\tremaining: 5m 13s\n",
            "221:\tlearn: 0.3406099\ttotal: 1m 29s\tremaining: 5m 13s\n",
            "222:\tlearn: 0.3401091\ttotal: 1m 30s\tremaining: 5m 14s\n",
            "223:\tlearn: 0.3394572\ttotal: 1m 30s\tremaining: 5m 14s\n",
            "224:\tlearn: 0.3389353\ttotal: 1m 31s\tremaining: 5m 14s\n",
            "225:\tlearn: 0.3382676\ttotal: 1m 31s\tremaining: 5m 14s\n",
            "226:\tlearn: 0.3375938\ttotal: 1m 32s\tremaining: 5m 13s\n",
            "227:\tlearn: 0.3371846\ttotal: 1m 32s\tremaining: 5m 12s\n",
            "228:\tlearn: 0.3367083\ttotal: 1m 32s\tremaining: 5m 12s\n",
            "229:\tlearn: 0.3363684\ttotal: 1m 33s\tremaining: 5m 11s\n",
            "230:\tlearn: 0.3357763\ttotal: 1m 33s\tremaining: 5m 11s\n",
            "231:\tlearn: 0.3354035\ttotal: 1m 33s\tremaining: 5m 10s\n",
            "232:\tlearn: 0.3351560\ttotal: 1m 34s\tremaining: 5m 10s\n",
            "233:\tlearn: 0.3348337\ttotal: 1m 34s\tremaining: 5m 9s\n",
            "234:\tlearn: 0.3345922\ttotal: 1m 34s\tremaining: 5m 9s\n",
            "235:\tlearn: 0.3343207\ttotal: 1m 35s\tremaining: 5m 8s\n",
            "236:\tlearn: 0.3340996\ttotal: 1m 35s\tremaining: 5m 8s\n",
            "237:\tlearn: 0.3339343\ttotal: 1m 36s\tremaining: 5m 7s\n",
            "238:\tlearn: 0.3335229\ttotal: 1m 36s\tremaining: 5m 6s\n",
            "239:\tlearn: 0.3331544\ttotal: 1m 36s\tremaining: 5m 6s\n",
            "240:\tlearn: 0.3327285\ttotal: 1m 37s\tremaining: 5m 5s\n",
            "241:\tlearn: 0.3322703\ttotal: 1m 37s\tremaining: 5m 5s\n",
            "242:\tlearn: 0.3317940\ttotal: 1m 37s\tremaining: 5m 4s\n",
            "243:\tlearn: 0.3313290\ttotal: 1m 38s\tremaining: 5m 4s\n",
            "244:\tlearn: 0.3311259\ttotal: 1m 38s\tremaining: 5m 3s\n",
            "245:\tlearn: 0.3307001\ttotal: 1m 38s\tremaining: 5m 3s\n",
            "246:\tlearn: 0.3302527\ttotal: 1m 39s\tremaining: 5m 2s\n",
            "247:\tlearn: 0.3299468\ttotal: 1m 39s\tremaining: 5m 2s\n",
            "248:\tlearn: 0.3294280\ttotal: 1m 40s\tremaining: 5m 1s\n",
            "249:\tlearn: 0.3291520\ttotal: 1m 40s\tremaining: 5m 1s\n",
            "250:\tlearn: 0.3288770\ttotal: 1m 41s\tremaining: 5m 1s\n",
            "251:\tlearn: 0.3286018\ttotal: 1m 41s\tremaining: 5m 1s\n",
            "252:\tlearn: 0.3280998\ttotal: 1m 42s\tremaining: 5m 1s\n",
            "253:\tlearn: 0.3278270\ttotal: 1m 42s\tremaining: 5m 2s\n",
            "254:\tlearn: 0.3274346\ttotal: 1m 43s\tremaining: 5m 2s\n",
            "255:\tlearn: 0.3271274\ttotal: 1m 44s\tremaining: 5m 2s\n",
            "256:\tlearn: 0.3264545\ttotal: 1m 44s\tremaining: 5m 1s\n",
            "257:\tlearn: 0.3258924\ttotal: 1m 44s\tremaining: 5m 1s\n",
            "258:\tlearn: 0.3254645\ttotal: 1m 45s\tremaining: 5m\n",
            "259:\tlearn: 0.3251782\ttotal: 1m 45s\tremaining: 5m\n",
            "260:\tlearn: 0.3249800\ttotal: 1m 45s\tremaining: 4m 59s\n",
            "261:\tlearn: 0.3248238\ttotal: 1m 46s\tremaining: 4m 59s\n",
            "262:\tlearn: 0.3243764\ttotal: 1m 46s\tremaining: 4m 58s\n",
            "263:\tlearn: 0.3241061\ttotal: 1m 46s\tremaining: 4m 58s\n",
            "264:\tlearn: 0.3236433\ttotal: 1m 47s\tremaining: 4m 57s\n",
            "265:\tlearn: 0.3232645\ttotal: 1m 47s\tremaining: 4m 57s\n",
            "266:\tlearn: 0.3228131\ttotal: 1m 48s\tremaining: 4m 56s\n",
            "267:\tlearn: 0.3223979\ttotal: 1m 48s\tremaining: 4m 55s\n",
            "268:\tlearn: 0.3220595\ttotal: 1m 48s\tremaining: 4m 55s\n",
            "269:\tlearn: 0.3218390\ttotal: 1m 49s\tremaining: 4m 54s\n",
            "270:\tlearn: 0.3214792\ttotal: 1m 49s\tremaining: 4m 54s\n",
            "271:\tlearn: 0.3211341\ttotal: 1m 49s\tremaining: 4m 53s\n",
            "272:\tlearn: 0.3208140\ttotal: 1m 50s\tremaining: 4m 53s\n",
            "273:\tlearn: 0.3203465\ttotal: 1m 50s\tremaining: 4m 52s\n",
            "274:\tlearn: 0.3198647\ttotal: 1m 50s\tremaining: 4m 52s\n",
            "275:\tlearn: 0.3193253\ttotal: 1m 51s\tremaining: 4m 51s\n",
            "276:\tlearn: 0.3191683\ttotal: 1m 51s\tremaining: 4m 51s\n",
            "277:\tlearn: 0.3187408\ttotal: 1m 52s\tremaining: 4m 50s\n",
            "278:\tlearn: 0.3183934\ttotal: 1m 52s\tremaining: 4m 50s\n",
            "279:\tlearn: 0.3181190\ttotal: 1m 52s\tremaining: 4m 49s\n",
            "280:\tlearn: 0.3175552\ttotal: 1m 53s\tremaining: 4m 49s\n",
            "281:\tlearn: 0.3171035\ttotal: 1m 53s\tremaining: 4m 48s\n",
            "282:\tlearn: 0.3167284\ttotal: 1m 53s\tremaining: 4m 48s\n",
            "283:\tlearn: 0.3164371\ttotal: 1m 54s\tremaining: 4m 48s\n",
            "284:\tlearn: 0.3160160\ttotal: 1m 54s\tremaining: 4m 48s\n",
            "285:\tlearn: 0.3155673\ttotal: 1m 55s\tremaining: 4m 48s\n",
            "286:\tlearn: 0.3151037\ttotal: 1m 56s\tremaining: 4m 48s\n",
            "287:\tlearn: 0.3148906\ttotal: 1m 56s\tremaining: 4m 48s\n",
            "288:\tlearn: 0.3145171\ttotal: 1m 57s\tremaining: 4m 47s\n",
            "289:\tlearn: 0.3139646\ttotal: 1m 57s\tremaining: 4m 47s\n",
            "290:\tlearn: 0.3136021\ttotal: 1m 57s\tremaining: 4m 46s\n",
            "291:\tlearn: 0.3131650\ttotal: 1m 58s\tremaining: 4m 46s\n",
            "292:\tlearn: 0.3129539\ttotal: 1m 58s\tremaining: 4m 45s\n",
            "293:\tlearn: 0.3127028\ttotal: 1m 58s\tremaining: 4m 45s\n",
            "294:\tlearn: 0.3124829\ttotal: 1m 59s\tremaining: 4m 44s\n",
            "295:\tlearn: 0.3120820\ttotal: 1m 59s\tremaining: 4m 44s\n",
            "296:\tlearn: 0.3117601\ttotal: 1m 59s\tremaining: 4m 43s\n",
            "297:\tlearn: 0.3112346\ttotal: 2m\tremaining: 4m 43s\n",
            "298:\tlearn: 0.3109372\ttotal: 2m\tremaining: 4m 42s\n",
            "299:\tlearn: 0.3105632\ttotal: 2m 1s\tremaining: 4m 42s\n",
            "300:\tlearn: 0.3104483\ttotal: 2m 1s\tremaining: 4m 41s\n",
            "301:\tlearn: 0.3102479\ttotal: 2m 1s\tremaining: 4m 41s\n",
            "302:\tlearn: 0.3100761\ttotal: 2m 2s\tremaining: 4m 40s\n",
            "303:\tlearn: 0.3098576\ttotal: 2m 2s\tremaining: 4m 40s\n",
            "304:\tlearn: 0.3093693\ttotal: 2m 2s\tremaining: 4m 40s\n",
            "305:\tlearn: 0.3091283\ttotal: 2m 3s\tremaining: 4m 39s\n",
            "306:\tlearn: 0.3088741\ttotal: 2m 3s\tremaining: 4m 39s\n",
            "307:\tlearn: 0.3085906\ttotal: 2m 3s\tremaining: 4m 38s\n",
            "308:\tlearn: 0.3082702\ttotal: 2m 4s\tremaining: 4m 38s\n",
            "309:\tlearn: 0.3077085\ttotal: 2m 4s\tremaining: 4m 37s\n",
            "310:\tlearn: 0.3073360\ttotal: 2m 5s\tremaining: 4m 37s\n",
            "311:\tlearn: 0.3070699\ttotal: 2m 5s\tremaining: 4m 36s\n",
            "312:\tlearn: 0.3066748\ttotal: 2m 5s\tremaining: 4m 36s\n",
            "313:\tlearn: 0.3063479\ttotal: 2m 6s\tremaining: 4m 35s\n",
            "314:\tlearn: 0.3060773\ttotal: 2m 6s\tremaining: 4m 35s\n",
            "315:\tlearn: 0.3058489\ttotal: 2m 7s\tremaining: 4m 35s\n",
            "316:\tlearn: 0.3056550\ttotal: 2m 7s\tremaining: 4m 35s\n",
            "317:\tlearn: 0.3054016\ttotal: 2m 8s\tremaining: 4m 35s\n",
            "318:\tlearn: 0.3048485\ttotal: 2m 8s\tremaining: 4m 35s\n",
            "319:\tlearn: 0.3042544\ttotal: 2m 9s\tremaining: 4m 34s\n",
            "320:\tlearn: 0.3037855\ttotal: 2m 9s\tremaining: 4m 34s\n",
            "321:\tlearn: 0.3033005\ttotal: 2m 10s\tremaining: 4m 35s\n",
            "322:\tlearn: 0.3030725\ttotal: 2m 11s\tremaining: 4m 34s\n",
            "323:\tlearn: 0.3029653\ttotal: 2m 11s\tremaining: 4m 34s\n",
            "324:\tlearn: 0.3027345\ttotal: 2m 11s\tremaining: 4m 33s\n",
            "325:\tlearn: 0.3024849\ttotal: 2m 12s\tremaining: 4m 33s\n",
            "326:\tlearn: 0.3022389\ttotal: 2m 12s\tremaining: 4m 32s\n",
            "327:\tlearn: 0.3019779\ttotal: 2m 12s\tremaining: 4m 32s\n",
            "328:\tlearn: 0.3017456\ttotal: 2m 13s\tremaining: 4m 31s\n",
            "329:\tlearn: 0.3014471\ttotal: 2m 13s\tremaining: 4m 31s\n",
            "330:\tlearn: 0.3013129\ttotal: 2m 13s\tremaining: 4m 30s\n",
            "331:\tlearn: 0.3008389\ttotal: 2m 14s\tremaining: 4m 30s\n",
            "332:\tlearn: 0.3006107\ttotal: 2m 14s\tremaining: 4m 29s\n",
            "333:\tlearn: 0.3003613\ttotal: 2m 15s\tremaining: 4m 29s\n",
            "334:\tlearn: 0.2999964\ttotal: 2m 15s\tremaining: 4m 28s\n",
            "335:\tlearn: 0.2997044\ttotal: 2m 15s\tremaining: 4m 28s\n",
            "336:\tlearn: 0.2993885\ttotal: 2m 16s\tremaining: 4m 27s\n",
            "337:\tlearn: 0.2989184\ttotal: 2m 16s\tremaining: 4m 27s\n",
            "338:\tlearn: 0.2984776\ttotal: 2m 16s\tremaining: 4m 26s\n",
            "339:\tlearn: 0.2980317\ttotal: 2m 17s\tremaining: 4m 26s\n",
            "340:\tlearn: 0.2979376\ttotal: 2m 17s\tremaining: 4m 25s\n",
            "341:\tlearn: 0.2975671\ttotal: 2m 17s\tremaining: 4m 25s\n",
            "342:\tlearn: 0.2973876\ttotal: 2m 18s\tremaining: 4m 25s\n",
            "343:\tlearn: 0.2969735\ttotal: 2m 18s\tremaining: 4m 24s\n",
            "344:\tlearn: 0.2967071\ttotal: 2m 19s\tremaining: 4m 24s\n",
            "345:\tlearn: 0.2963934\ttotal: 2m 19s\tremaining: 4m 24s\n",
            "346:\tlearn: 0.2960502\ttotal: 2m 20s\tremaining: 4m 24s\n",
            "347:\tlearn: 0.2955724\ttotal: 2m 21s\tremaining: 4m 24s\n",
            "348:\tlearn: 0.2954071\ttotal: 2m 21s\tremaining: 4m 24s\n",
            "349:\tlearn: 0.2951813\ttotal: 2m 22s\tremaining: 4m 23s\n",
            "350:\tlearn: 0.2948654\ttotal: 2m 22s\tremaining: 4m 23s\n",
            "351:\tlearn: 0.2946143\ttotal: 2m 22s\tremaining: 4m 22s\n",
            "352:\tlearn: 0.2943112\ttotal: 2m 23s\tremaining: 4m 22s\n",
            "353:\tlearn: 0.2941999\ttotal: 2m 23s\tremaining: 4m 21s\n",
            "354:\tlearn: 0.2938921\ttotal: 2m 23s\tremaining: 4m 21s\n",
            "355:\tlearn: 0.2933517\ttotal: 2m 24s\tremaining: 4m 20s\n",
            "356:\tlearn: 0.2930579\ttotal: 2m 24s\tremaining: 4m 20s\n",
            "357:\tlearn: 0.2928403\ttotal: 2m 24s\tremaining: 4m 19s\n",
            "358:\tlearn: 0.2923506\ttotal: 2m 25s\tremaining: 4m 19s\n",
            "359:\tlearn: 0.2921764\ttotal: 2m 25s\tremaining: 4m 18s\n",
            "360:\tlearn: 0.2918389\ttotal: 2m 25s\tremaining: 4m 18s\n",
            "361:\tlearn: 0.2915487\ttotal: 2m 26s\tremaining: 4m 17s\n",
            "362:\tlearn: 0.2913483\ttotal: 2m 26s\tremaining: 4m 17s\n",
            "363:\tlearn: 0.2908793\ttotal: 2m 27s\tremaining: 4m 17s\n",
            "364:\tlearn: 0.2907268\ttotal: 2m 27s\tremaining: 4m 16s\n",
            "365:\tlearn: 0.2904186\ttotal: 2m 27s\tremaining: 4m 16s\n",
            "366:\tlearn: 0.2903485\ttotal: 2m 28s\tremaining: 4m 15s\n",
            "367:\tlearn: 0.2899916\ttotal: 2m 28s\tremaining: 4m 15s\n",
            "368:\tlearn: 0.2897673\ttotal: 2m 29s\tremaining: 4m 14s\n",
            "369:\tlearn: 0.2896307\ttotal: 2m 29s\tremaining: 4m 14s\n",
            "370:\tlearn: 0.2893555\ttotal: 2m 29s\tremaining: 4m 13s\n",
            "371:\tlearn: 0.2888627\ttotal: 2m 30s\tremaining: 4m 13s\n",
            "372:\tlearn: 0.2886314\ttotal: 2m 30s\tremaining: 4m 12s\n",
            "373:\tlearn: 0.2882699\ttotal: 2m 30s\tremaining: 4m 12s\n",
            "374:\tlearn: 0.2881355\ttotal: 2m 31s\tremaining: 4m 11s\n",
            "375:\tlearn: 0.2879129\ttotal: 2m 31s\tremaining: 4m 11s\n",
            "376:\tlearn: 0.2876694\ttotal: 2m 32s\tremaining: 4m 11s\n",
            "377:\tlearn: 0.2874147\ttotal: 2m 32s\tremaining: 4m 11s\n",
            "378:\tlearn: 0.2871881\ttotal: 2m 33s\tremaining: 4m 11s\n",
            "379:\tlearn: 0.2869439\ttotal: 2m 33s\tremaining: 4m 11s\n",
            "380:\tlearn: 0.2866542\ttotal: 2m 34s\tremaining: 4m 10s\n",
            "381:\tlearn: 0.2864266\ttotal: 2m 34s\tremaining: 4m 10s\n",
            "382:\tlearn: 0.2863309\ttotal: 2m 35s\tremaining: 4m 9s\n",
            "383:\tlearn: 0.2861700\ttotal: 2m 35s\tremaining: 4m 9s\n",
            "384:\tlearn: 0.2859246\ttotal: 2m 35s\tremaining: 4m 9s\n",
            "385:\tlearn: 0.2856647\ttotal: 2m 36s\tremaining: 4m 8s\n",
            "386:\tlearn: 0.2853638\ttotal: 2m 36s\tremaining: 4m 8s\n",
            "387:\tlearn: 0.2851041\ttotal: 2m 36s\tremaining: 4m 7s\n",
            "388:\tlearn: 0.2848443\ttotal: 2m 37s\tremaining: 4m 7s\n",
            "389:\tlearn: 0.2844404\ttotal: 2m 37s\tremaining: 4m 6s\n",
            "390:\tlearn: 0.2842857\ttotal: 2m 38s\tremaining: 4m 6s\n",
            "391:\tlearn: 0.2841603\ttotal: 2m 38s\tremaining: 4m 5s\n",
            "392:\tlearn: 0.2839692\ttotal: 2m 38s\tremaining: 4m 5s\n",
            "393:\tlearn: 0.2838809\ttotal: 2m 39s\tremaining: 4m 4s\n",
            "394:\tlearn: 0.2834548\ttotal: 2m 39s\tremaining: 4m 4s\n",
            "395:\tlearn: 0.2830823\ttotal: 2m 39s\tremaining: 4m 3s\n",
            "396:\tlearn: 0.2826727\ttotal: 2m 40s\tremaining: 4m 3s\n",
            "397:\tlearn: 0.2823870\ttotal: 2m 40s\tremaining: 4m 2s\n",
            "398:\tlearn: 0.2821004\ttotal: 2m 40s\tremaining: 4m 2s\n",
            "399:\tlearn: 0.2818595\ttotal: 2m 41s\tremaining: 4m 2s\n",
            "400:\tlearn: 0.2817425\ttotal: 2m 41s\tremaining: 4m 1s\n",
            "401:\tlearn: 0.2813411\ttotal: 2m 42s\tremaining: 4m 1s\n",
            "402:\tlearn: 0.2810360\ttotal: 2m 42s\tremaining: 4m\n",
            "403:\tlearn: 0.2809257\ttotal: 2m 42s\tremaining: 4m\n",
            "404:\tlearn: 0.2806377\ttotal: 2m 43s\tremaining: 3m 59s\n",
            "405:\tlearn: 0.2803331\ttotal: 2m 43s\tremaining: 3m 59s\n",
            "406:\tlearn: 0.2802268\ttotal: 2m 43s\tremaining: 3m 58s\n",
            "407:\tlearn: 0.2799560\ttotal: 2m 44s\tremaining: 3m 58s\n",
            "408:\tlearn: 0.2797729\ttotal: 2m 44s\tremaining: 3m 58s\n",
            "409:\tlearn: 0.2795116\ttotal: 2m 45s\tremaining: 3m 58s\n",
            "410:\tlearn: 0.2792840\ttotal: 2m 46s\tremaining: 3m 57s\n",
            "411:\tlearn: 0.2790364\ttotal: 2m 46s\tremaining: 3m 57s\n",
            "412:\tlearn: 0.2788446\ttotal: 2m 47s\tremaining: 3m 57s\n",
            "413:\tlearn: 0.2786801\ttotal: 2m 47s\tremaining: 3m 56s\n",
            "414:\tlearn: 0.2784351\ttotal: 2m 47s\tremaining: 3m 56s\n",
            "415:\tlearn: 0.2781683\ttotal: 2m 48s\tremaining: 3m 56s\n",
            "416:\tlearn: 0.2778413\ttotal: 2m 48s\tremaining: 3m 55s\n",
            "417:\tlearn: 0.2775460\ttotal: 2m 48s\tremaining: 3m 55s\n",
            "418:\tlearn: 0.2773007\ttotal: 2m 49s\tremaining: 3m 54s\n",
            "419:\tlearn: 0.2771539\ttotal: 2m 49s\tremaining: 3m 54s\n",
            "420:\tlearn: 0.2769387\ttotal: 2m 49s\tremaining: 3m 53s\n",
            "421:\tlearn: 0.2764862\ttotal: 2m 50s\tremaining: 3m 53s\n",
            "422:\tlearn: 0.2761851\ttotal: 2m 50s\tremaining: 3m 52s\n",
            "423:\tlearn: 0.2758930\ttotal: 2m 51s\tremaining: 3m 52s\n",
            "424:\tlearn: 0.2755972\ttotal: 2m 51s\tremaining: 3m 51s\n",
            "425:\tlearn: 0.2754172\ttotal: 2m 51s\tremaining: 3m 51s\n",
            "426:\tlearn: 0.2750290\ttotal: 2m 52s\tremaining: 3m 51s\n",
            "427:\tlearn: 0.2748158\ttotal: 2m 52s\tremaining: 3m 50s\n",
            "428:\tlearn: 0.2744871\ttotal: 2m 52s\tremaining: 3m 50s\n",
            "429:\tlearn: 0.2741545\ttotal: 2m 53s\tremaining: 3m 49s\n",
            "430:\tlearn: 0.2739179\ttotal: 2m 53s\tremaining: 3m 49s\n",
            "431:\tlearn: 0.2737767\ttotal: 2m 54s\tremaining: 3m 48s\n",
            "432:\tlearn: 0.2735800\ttotal: 2m 54s\tremaining: 3m 48s\n",
            "433:\tlearn: 0.2734259\ttotal: 2m 54s\tremaining: 3m 47s\n",
            "434:\tlearn: 0.2731856\ttotal: 2m 55s\tremaining: 3m 47s\n",
            "435:\tlearn: 0.2730446\ttotal: 2m 55s\tremaining: 3m 47s\n",
            "436:\tlearn: 0.2729908\ttotal: 2m 55s\tremaining: 3m 46s\n",
            "437:\tlearn: 0.2728101\ttotal: 2m 56s\tremaining: 3m 46s\n",
            "438:\tlearn: 0.2726960\ttotal: 2m 56s\tremaining: 3m 45s\n",
            "439:\tlearn: 0.2724970\ttotal: 2m 57s\tremaining: 3m 45s\n",
            "440:\tlearn: 0.2723875\ttotal: 2m 57s\tremaining: 3m 45s\n",
            "441:\tlearn: 0.2721723\ttotal: 2m 58s\tremaining: 3m 45s\n",
            "442:\tlearn: 0.2719880\ttotal: 2m 59s\tremaining: 3m 45s\n",
            "443:\tlearn: 0.2719078\ttotal: 2m 59s\tremaining: 3m 44s\n",
            "444:\tlearn: 0.2717055\ttotal: 2m 59s\tremaining: 3m 44s\n",
            "445:\tlearn: 0.2715667\ttotal: 3m\tremaining: 3m 44s\n",
            "446:\tlearn: 0.2711652\ttotal: 3m\tremaining: 3m 43s\n",
            "447:\tlearn: 0.2709312\ttotal: 3m 1s\tremaining: 3m 43s\n",
            "448:\tlearn: 0.2707631\ttotal: 3m 1s\tremaining: 3m 42s\n",
            "449:\tlearn: 0.2706115\ttotal: 3m 1s\tremaining: 3m 42s\n",
            "450:\tlearn: 0.2702934\ttotal: 3m 2s\tremaining: 3m 41s\n",
            "451:\tlearn: 0.2700765\ttotal: 3m 2s\tremaining: 3m 41s\n",
            "452:\tlearn: 0.2697637\ttotal: 3m 2s\tremaining: 3m 40s\n",
            "453:\tlearn: 0.2694671\ttotal: 3m 3s\tremaining: 3m 40s\n",
            "454:\tlearn: 0.2693241\ttotal: 3m 3s\tremaining: 3m 40s\n",
            "455:\tlearn: 0.2691760\ttotal: 3m 4s\tremaining: 3m 39s\n",
            "456:\tlearn: 0.2687440\ttotal: 3m 4s\tremaining: 3m 39s\n",
            "457:\tlearn: 0.2685807\ttotal: 3m 4s\tremaining: 3m 38s\n",
            "458:\tlearn: 0.2682852\ttotal: 3m 5s\tremaining: 3m 38s\n",
            "459:\tlearn: 0.2680317\ttotal: 3m 5s\tremaining: 3m 37s\n",
            "460:\tlearn: 0.2678492\ttotal: 3m 5s\tremaining: 3m 37s\n",
            "461:\tlearn: 0.2676439\ttotal: 3m 6s\tremaining: 3m 36s\n",
            "462:\tlearn: 0.2672688\ttotal: 3m 6s\tremaining: 3m 36s\n",
            "463:\tlearn: 0.2671017\ttotal: 3m 7s\tremaining: 3m 36s\n",
            "464:\tlearn: 0.2668821\ttotal: 3m 7s\tremaining: 3m 35s\n",
            "465:\tlearn: 0.2665903\ttotal: 3m 7s\tremaining: 3m 35s\n",
            "466:\tlearn: 0.2664264\ttotal: 3m 8s\tremaining: 3m 34s\n",
            "467:\tlearn: 0.2663046\ttotal: 3m 8s\tremaining: 3m 34s\n",
            "468:\tlearn: 0.2660641\ttotal: 3m 8s\tremaining: 3m 33s\n",
            "469:\tlearn: 0.2658916\ttotal: 3m 9s\tremaining: 3m 33s\n",
            "470:\tlearn: 0.2656370\ttotal: 3m 9s\tremaining: 3m 32s\n",
            "471:\tlearn: 0.2654533\ttotal: 3m 10s\tremaining: 3m 32s\n",
            "472:\tlearn: 0.2652139\ttotal: 3m 10s\tremaining: 3m 32s\n",
            "473:\tlearn: 0.2649613\ttotal: 3m 11s\tremaining: 3m 32s\n",
            "474:\tlearn: 0.2648155\ttotal: 3m 12s\tremaining: 3m 32s\n",
            "475:\tlearn: 0.2645993\ttotal: 3m 12s\tremaining: 3m 31s\n",
            "476:\tlearn: 0.2643554\ttotal: 3m 12s\tremaining: 3m 31s\n",
            "477:\tlearn: 0.2641917\ttotal: 3m 13s\tremaining: 3m 31s\n",
            "478:\tlearn: 0.2639870\ttotal: 3m 13s\tremaining: 3m 30s\n",
            "479:\tlearn: 0.2638231\ttotal: 3m 13s\tremaining: 3m 30s\n",
            "480:\tlearn: 0.2636419\ttotal: 3m 14s\tremaining: 3m 29s\n",
            "481:\tlearn: 0.2634699\ttotal: 3m 14s\tremaining: 3m 29s\n",
            "482:\tlearn: 0.2632577\ttotal: 3m 15s\tremaining: 3m 28s\n",
            "483:\tlearn: 0.2630474\ttotal: 3m 15s\tremaining: 3m 28s\n",
            "484:\tlearn: 0.2627720\ttotal: 3m 15s\tremaining: 3m 27s\n",
            "485:\tlearn: 0.2625466\ttotal: 3m 16s\tremaining: 3m 27s\n",
            "486:\tlearn: 0.2621687\ttotal: 3m 16s\tremaining: 3m 27s\n",
            "487:\tlearn: 0.2619579\ttotal: 3m 16s\tremaining: 3m 26s\n",
            "488:\tlearn: 0.2616212\ttotal: 3m 17s\tremaining: 3m 26s\n",
            "489:\tlearn: 0.2614098\ttotal: 3m 17s\tremaining: 3m 25s\n",
            "490:\tlearn: 0.2611723\ttotal: 3m 18s\tremaining: 3m 25s\n",
            "491:\tlearn: 0.2609468\ttotal: 3m 18s\tremaining: 3m 24s\n",
            "492:\tlearn: 0.2607896\ttotal: 3m 18s\tremaining: 3m 24s\n",
            "493:\tlearn: 0.2605850\ttotal: 3m 19s\tremaining: 3m 23s\n",
            "494:\tlearn: 0.2604120\ttotal: 3m 19s\tremaining: 3m 23s\n",
            "495:\tlearn: 0.2602040\ttotal: 3m 19s\tremaining: 3m 23s\n",
            "496:\tlearn: 0.2599294\ttotal: 3m 20s\tremaining: 3m 22s\n",
            "497:\tlearn: 0.2596136\ttotal: 3m 20s\tremaining: 3m 22s\n",
            "498:\tlearn: 0.2594129\ttotal: 3m 20s\tremaining: 3m 21s\n",
            "499:\tlearn: 0.2590898\ttotal: 3m 21s\tremaining: 3m 21s\n",
            "500:\tlearn: 0.2588802\ttotal: 3m 21s\tremaining: 3m 20s\n",
            "501:\tlearn: 0.2586383\ttotal: 3m 22s\tremaining: 3m 20s\n",
            "502:\tlearn: 0.2583576\ttotal: 3m 22s\tremaining: 3m 20s\n",
            "503:\tlearn: 0.2582038\ttotal: 3m 23s\tremaining: 3m 19s\n",
            "504:\tlearn: 0.2579446\ttotal: 3m 23s\tremaining: 3m 19s\n",
            "505:\tlearn: 0.2577216\ttotal: 3m 24s\tremaining: 3m 19s\n",
            "506:\tlearn: 0.2575534\ttotal: 3m 24s\tremaining: 3m 19s\n",
            "507:\tlearn: 0.2573875\ttotal: 3m 25s\tremaining: 3m 18s\n",
            "508:\tlearn: 0.2569480\ttotal: 3m 25s\tremaining: 3m 18s\n",
            "509:\tlearn: 0.2566723\ttotal: 3m 26s\tremaining: 3m 17s\n",
            "510:\tlearn: 0.2563843\ttotal: 3m 26s\tremaining: 3m 17s\n",
            "511:\tlearn: 0.2559810\ttotal: 3m 26s\tremaining: 3m 17s\n",
            "512:\tlearn: 0.2556097\ttotal: 3m 27s\tremaining: 3m 16s\n",
            "513:\tlearn: 0.2554260\ttotal: 3m 27s\tremaining: 3m 16s\n",
            "514:\tlearn: 0.2553171\ttotal: 3m 27s\tremaining: 3m 15s\n",
            "515:\tlearn: 0.2550955\ttotal: 3m 28s\tremaining: 3m 15s\n",
            "516:\tlearn: 0.2549501\ttotal: 3m 28s\tremaining: 3m 14s\n",
            "517:\tlearn: 0.2548004\ttotal: 3m 29s\tremaining: 3m 14s\n",
            "518:\tlearn: 0.2546005\ttotal: 3m 29s\tremaining: 3m 14s\n",
            "519:\tlearn: 0.2543796\ttotal: 3m 29s\tremaining: 3m 13s\n",
            "520:\tlearn: 0.2541509\ttotal: 3m 30s\tremaining: 3m 13s\n",
            "521:\tlearn: 0.2540747\ttotal: 3m 30s\tremaining: 3m 12s\n",
            "522:\tlearn: 0.2539196\ttotal: 3m 30s\tremaining: 3m 12s\n",
            "523:\tlearn: 0.2536444\ttotal: 3m 31s\tremaining: 3m 11s\n",
            "524:\tlearn: 0.2535224\ttotal: 3m 31s\tremaining: 3m 11s\n",
            "525:\tlearn: 0.2532775\ttotal: 3m 31s\tremaining: 3m 10s\n",
            "526:\tlearn: 0.2530101\ttotal: 3m 32s\tremaining: 3m 10s\n",
            "527:\tlearn: 0.2528070\ttotal: 3m 32s\tremaining: 3m 10s\n",
            "528:\tlearn: 0.2525524\ttotal: 3m 33s\tremaining: 3m 9s\n",
            "529:\tlearn: 0.2524833\ttotal: 3m 33s\tremaining: 3m 9s\n",
            "530:\tlearn: 0.2523406\ttotal: 3m 33s\tremaining: 3m 8s\n",
            "531:\tlearn: 0.2521302\ttotal: 3m 34s\tremaining: 3m 8s\n",
            "532:\tlearn: 0.2520047\ttotal: 3m 34s\tremaining: 3m 7s\n",
            "533:\tlearn: 0.2518433\ttotal: 3m 34s\tremaining: 3m 7s\n",
            "534:\tlearn: 0.2517108\ttotal: 3m 35s\tremaining: 3m 7s\n",
            "535:\tlearn: 0.2515681\ttotal: 3m 36s\tremaining: 3m 7s\n",
            "536:\tlearn: 0.2512719\ttotal: 3m 36s\tremaining: 3m 6s\n",
            "537:\tlearn: 0.2510394\ttotal: 3m 37s\tremaining: 3m 6s\n",
            "538:\tlearn: 0.2509665\ttotal: 3m 37s\tremaining: 3m 6s\n",
            "539:\tlearn: 0.2508256\ttotal: 3m 38s\tremaining: 3m 5s\n",
            "540:\tlearn: 0.2506030\ttotal: 3m 38s\tremaining: 3m 5s\n",
            "541:\tlearn: 0.2501600\ttotal: 3m 38s\tremaining: 3m 4s\n",
            "542:\tlearn: 0.2500286\ttotal: 3m 39s\tremaining: 3m 4s\n",
            "543:\tlearn: 0.2497260\ttotal: 3m 39s\tremaining: 3m 4s\n",
            "544:\tlearn: 0.2495736\ttotal: 3m 40s\tremaining: 3m 3s\n",
            "545:\tlearn: 0.2494420\ttotal: 3m 40s\tremaining: 3m 3s\n",
            "546:\tlearn: 0.2492627\ttotal: 3m 40s\tremaining: 3m 2s\n",
            "547:\tlearn: 0.2491447\ttotal: 3m 41s\tremaining: 3m 2s\n",
            "548:\tlearn: 0.2490165\ttotal: 3m 41s\tremaining: 3m 1s\n",
            "549:\tlearn: 0.2488792\ttotal: 3m 41s\tremaining: 3m 1s\n",
            "550:\tlearn: 0.2485065\ttotal: 3m 42s\tremaining: 3m 1s\n",
            "551:\tlearn: 0.2482162\ttotal: 3m 42s\tremaining: 3m\n",
            "552:\tlearn: 0.2480384\ttotal: 3m 42s\tremaining: 3m\n",
            "553:\tlearn: 0.2478375\ttotal: 3m 43s\tremaining: 2m 59s\n",
            "554:\tlearn: 0.2475281\ttotal: 3m 43s\tremaining: 2m 59s\n",
            "555:\tlearn: 0.2471840\ttotal: 3m 44s\tremaining: 2m 58s\n",
            "556:\tlearn: 0.2470310\ttotal: 3m 44s\tremaining: 2m 58s\n",
            "557:\tlearn: 0.2469214\ttotal: 3m 44s\tremaining: 2m 58s\n",
            "558:\tlearn: 0.2466344\ttotal: 3m 45s\tremaining: 2m 57s\n",
            "559:\tlearn: 0.2463843\ttotal: 3m 45s\tremaining: 2m 57s\n",
            "560:\tlearn: 0.2461659\ttotal: 3m 45s\tremaining: 2m 56s\n",
            "561:\tlearn: 0.2459876\ttotal: 3m 46s\tremaining: 2m 56s\n",
            "562:\tlearn: 0.2458093\ttotal: 3m 46s\tremaining: 2m 55s\n",
            "563:\tlearn: 0.2455102\ttotal: 3m 47s\tremaining: 2m 55s\n",
            "564:\tlearn: 0.2453244\ttotal: 3m 47s\tremaining: 2m 55s\n",
            "565:\tlearn: 0.2451069\ttotal: 3m 47s\tremaining: 2m 54s\n",
            "566:\tlearn: 0.2450028\ttotal: 3m 48s\tremaining: 2m 54s\n",
            "567:\tlearn: 0.2447086\ttotal: 3m 49s\tremaining: 2m 54s\n",
            "568:\tlearn: 0.2445346\ttotal: 3m 49s\tremaining: 2m 54s\n",
            "569:\tlearn: 0.2443192\ttotal: 3m 50s\tremaining: 2m 53s\n",
            "570:\tlearn: 0.2439992\ttotal: 3m 50s\tremaining: 2m 53s\n",
            "571:\tlearn: 0.2437981\ttotal: 3m 51s\tremaining: 2m 52s\n",
            "572:\tlearn: 0.2434604\ttotal: 3m 51s\tremaining: 2m 52s\n",
            "573:\tlearn: 0.2432245\ttotal: 3m 51s\tremaining: 2m 52s\n",
            "574:\tlearn: 0.2429829\ttotal: 3m 52s\tremaining: 2m 51s\n",
            "575:\tlearn: 0.2428730\ttotal: 3m 52s\tremaining: 2m 51s\n",
            "576:\tlearn: 0.2427443\ttotal: 3m 52s\tremaining: 2m 50s\n",
            "577:\tlearn: 0.2426287\ttotal: 3m 53s\tremaining: 2m 50s\n",
            "578:\tlearn: 0.2424368\ttotal: 3m 53s\tremaining: 2m 49s\n",
            "579:\tlearn: 0.2423276\ttotal: 3m 54s\tremaining: 2m 49s\n",
            "580:\tlearn: 0.2421353\ttotal: 3m 54s\tremaining: 2m 49s\n",
            "581:\tlearn: 0.2419533\ttotal: 3m 54s\tremaining: 2m 48s\n",
            "582:\tlearn: 0.2417915\ttotal: 3m 55s\tremaining: 2m 48s\n",
            "583:\tlearn: 0.2416452\ttotal: 3m 55s\tremaining: 2m 47s\n",
            "584:\tlearn: 0.2414167\ttotal: 3m 55s\tremaining: 2m 47s\n",
            "585:\tlearn: 0.2412350\ttotal: 3m 56s\tremaining: 2m 46s\n",
            "586:\tlearn: 0.2411062\ttotal: 3m 56s\tremaining: 2m 46s\n",
            "587:\tlearn: 0.2407608\ttotal: 3m 57s\tremaining: 2m 46s\n",
            "588:\tlearn: 0.2405630\ttotal: 3m 57s\tremaining: 2m 45s\n",
            "589:\tlearn: 0.2404777\ttotal: 3m 57s\tremaining: 2m 45s\n",
            "590:\tlearn: 0.2402837\ttotal: 3m 58s\tremaining: 2m 44s\n",
            "591:\tlearn: 0.2401013\ttotal: 3m 58s\tremaining: 2m 44s\n",
            "592:\tlearn: 0.2399794\ttotal: 3m 58s\tremaining: 2m 43s\n",
            "593:\tlearn: 0.2398389\ttotal: 3m 59s\tremaining: 2m 43s\n",
            "594:\tlearn: 0.2396494\ttotal: 3m 59s\tremaining: 2m 43s\n",
            "595:\tlearn: 0.2393436\ttotal: 3m 59s\tremaining: 2m 42s\n",
            "596:\tlearn: 0.2391948\ttotal: 4m\tremaining: 2m 42s\n",
            "597:\tlearn: 0.2390075\ttotal: 4m 1s\tremaining: 2m 42s\n",
            "598:\tlearn: 0.2389140\ttotal: 4m 1s\tremaining: 2m 41s\n",
            "599:\tlearn: 0.2388463\ttotal: 4m 2s\tremaining: 2m 41s\n",
            "600:\tlearn: 0.2387082\ttotal: 4m 2s\tremaining: 2m 41s\n",
            "601:\tlearn: 0.2384021\ttotal: 4m 3s\tremaining: 2m 40s\n",
            "602:\tlearn: 0.2382227\ttotal: 4m 3s\tremaining: 2m 40s\n",
            "603:\tlearn: 0.2379730\ttotal: 4m 3s\tremaining: 2m 39s\n",
            "604:\tlearn: 0.2378734\ttotal: 4m 4s\tremaining: 2m 39s\n",
            "605:\tlearn: 0.2376319\ttotal: 4m 4s\tremaining: 2m 39s\n",
            "606:\tlearn: 0.2375043\ttotal: 4m 5s\tremaining: 2m 38s\n",
            "607:\tlearn: 0.2372228\ttotal: 4m 5s\tremaining: 2m 38s\n",
            "608:\tlearn: 0.2370071\ttotal: 4m 5s\tremaining: 2m 37s\n",
            "609:\tlearn: 0.2368742\ttotal: 4m 6s\tremaining: 2m 37s\n",
            "610:\tlearn: 0.2365819\ttotal: 4m 6s\tremaining: 2m 36s\n",
            "611:\tlearn: 0.2364969\ttotal: 4m 6s\tremaining: 2m 36s\n",
            "612:\tlearn: 0.2362962\ttotal: 4m 7s\tremaining: 2m 36s\n",
            "613:\tlearn: 0.2359938\ttotal: 4m 7s\tremaining: 2m 35s\n",
            "614:\tlearn: 0.2358437\ttotal: 4m 7s\tremaining: 2m 35s\n",
            "615:\tlearn: 0.2356931\ttotal: 4m 8s\tremaining: 2m 34s\n",
            "616:\tlearn: 0.2355255\ttotal: 4m 8s\tremaining: 2m 34s\n",
            "617:\tlearn: 0.2353231\ttotal: 4m 9s\tremaining: 2m 33s\n",
            "618:\tlearn: 0.2350550\ttotal: 4m 9s\tremaining: 2m 33s\n",
            "619:\tlearn: 0.2348797\ttotal: 4m 9s\tremaining: 2m 33s\n",
            "620:\tlearn: 0.2346638\ttotal: 4m 10s\tremaining: 2m 32s\n",
            "621:\tlearn: 0.2344465\ttotal: 4m 10s\tremaining: 2m 32s\n",
            "622:\tlearn: 0.2342142\ttotal: 4m 10s\tremaining: 2m 31s\n",
            "623:\tlearn: 0.2340115\ttotal: 4m 11s\tremaining: 2m 31s\n",
            "624:\tlearn: 0.2337312\ttotal: 4m 11s\tremaining: 2m 30s\n",
            "625:\tlearn: 0.2335906\ttotal: 4m 12s\tremaining: 2m 30s\n",
            "626:\tlearn: 0.2333417\ttotal: 4m 12s\tremaining: 2m 30s\n",
            "627:\tlearn: 0.2331800\ttotal: 4m 12s\tremaining: 2m 29s\n",
            "628:\tlearn: 0.2328498\ttotal: 4m 13s\tremaining: 2m 29s\n",
            "629:\tlearn: 0.2327033\ttotal: 4m 14s\tremaining: 2m 29s\n",
            "630:\tlearn: 0.2326408\ttotal: 4m 14s\tremaining: 2m 28s\n",
            "631:\tlearn: 0.2325287\ttotal: 4m 15s\tremaining: 2m 28s\n",
            "632:\tlearn: 0.2324681\ttotal: 4m 15s\tremaining: 2m 28s\n",
            "633:\tlearn: 0.2322580\ttotal: 4m 15s\tremaining: 2m 27s\n",
            "634:\tlearn: 0.2320530\ttotal: 4m 16s\tremaining: 2m 27s\n",
            "635:\tlearn: 0.2318396\ttotal: 4m 16s\tremaining: 2m 26s\n",
            "636:\tlearn: 0.2317017\ttotal: 4m 17s\tremaining: 2m 26s\n",
            "637:\tlearn: 0.2313821\ttotal: 4m 17s\tremaining: 2m 26s\n",
            "638:\tlearn: 0.2312400\ttotal: 4m 17s\tremaining: 2m 25s\n",
            "639:\tlearn: 0.2310637\ttotal: 4m 18s\tremaining: 2m 25s\n",
            "640:\tlearn: 0.2309750\ttotal: 4m 18s\tremaining: 2m 24s\n",
            "641:\tlearn: 0.2308776\ttotal: 4m 18s\tremaining: 2m 24s\n",
            "642:\tlearn: 0.2307981\ttotal: 4m 19s\tremaining: 2m 23s\n",
            "643:\tlearn: 0.2307276\ttotal: 4m 19s\tremaining: 2m 23s\n",
            "644:\tlearn: 0.2305686\ttotal: 4m 19s\tremaining: 2m 23s\n",
            "645:\tlearn: 0.2303726\ttotal: 4m 20s\tremaining: 2m 22s\n",
            "646:\tlearn: 0.2299516\ttotal: 4m 20s\tremaining: 2m 22s\n",
            "647:\tlearn: 0.2296901\ttotal: 4m 21s\tremaining: 2m 21s\n",
            "648:\tlearn: 0.2295452\ttotal: 4m 21s\tremaining: 2m 21s\n",
            "649:\tlearn: 0.2293725\ttotal: 4m 21s\tremaining: 2m 20s\n",
            "650:\tlearn: 0.2292331\ttotal: 4m 22s\tremaining: 2m 20s\n",
            "651:\tlearn: 0.2290995\ttotal: 4m 22s\tremaining: 2m 20s\n",
            "652:\tlearn: 0.2288123\ttotal: 4m 22s\tremaining: 2m 19s\n",
            "653:\tlearn: 0.2286986\ttotal: 4m 23s\tremaining: 2m 19s\n",
            "654:\tlearn: 0.2285846\ttotal: 4m 23s\tremaining: 2m 18s\n",
            "655:\tlearn: 0.2284553\ttotal: 4m 23s\tremaining: 2m 18s\n",
            "656:\tlearn: 0.2283673\ttotal: 4m 24s\tremaining: 2m 18s\n",
            "657:\tlearn: 0.2280810\ttotal: 4m 24s\tremaining: 2m 17s\n",
            "658:\tlearn: 0.2279375\ttotal: 4m 25s\tremaining: 2m 17s\n",
            "659:\tlearn: 0.2278159\ttotal: 4m 25s\tremaining: 2m 16s\n",
            "660:\tlearn: 0.2275651\ttotal: 4m 26s\tremaining: 2m 16s\n",
            "661:\tlearn: 0.2274559\ttotal: 4m 26s\tremaining: 2m 16s\n",
            "662:\tlearn: 0.2273248\ttotal: 4m 27s\tremaining: 2m 15s\n",
            "663:\tlearn: 0.2271944\ttotal: 4m 27s\tremaining: 2m 15s\n",
            "664:\tlearn: 0.2269617\ttotal: 4m 28s\tremaining: 2m 15s\n",
            "665:\tlearn: 0.2266838\ttotal: 4m 28s\tremaining: 2m 14s\n",
            "666:\tlearn: 0.2265365\ttotal: 4m 29s\tremaining: 2m 14s\n",
            "667:\tlearn: 0.2263710\ttotal: 4m 29s\tremaining: 2m 13s\n",
            "668:\tlearn: 0.2261901\ttotal: 4m 29s\tremaining: 2m 13s\n",
            "669:\tlearn: 0.2260726\ttotal: 4m 30s\tremaining: 2m 13s\n",
            "670:\tlearn: 0.2259228\ttotal: 4m 30s\tremaining: 2m 12s\n",
            "671:\tlearn: 0.2256983\ttotal: 4m 30s\tremaining: 2m 12s\n",
            "672:\tlearn: 0.2255656\ttotal: 4m 31s\tremaining: 2m 11s\n",
            "673:\tlearn: 0.2252964\ttotal: 4m 31s\tremaining: 2m 11s\n",
            "674:\tlearn: 0.2252377\ttotal: 4m 31s\tremaining: 2m 10s\n",
            "675:\tlearn: 0.2250846\ttotal: 4m 32s\tremaining: 2m 10s\n",
            "676:\tlearn: 0.2249662\ttotal: 4m 32s\tremaining: 2m 10s\n",
            "677:\tlearn: 0.2248194\ttotal: 4m 33s\tremaining: 2m 9s\n",
            "678:\tlearn: 0.2245085\ttotal: 4m 33s\tremaining: 2m 9s\n",
            "679:\tlearn: 0.2242487\ttotal: 4m 33s\tremaining: 2m 8s\n",
            "680:\tlearn: 0.2241475\ttotal: 4m 34s\tremaining: 2m 8s\n",
            "681:\tlearn: 0.2240001\ttotal: 4m 34s\tremaining: 2m 8s\n",
            "682:\tlearn: 0.2239228\ttotal: 4m 34s\tremaining: 2m 7s\n",
            "683:\tlearn: 0.2237451\ttotal: 4m 35s\tremaining: 2m 7s\n",
            "684:\tlearn: 0.2236039\ttotal: 4m 35s\tremaining: 2m 6s\n",
            "685:\tlearn: 0.2235179\ttotal: 4m 36s\tremaining: 2m 6s\n",
            "686:\tlearn: 0.2233002\ttotal: 4m 36s\tremaining: 2m 5s\n",
            "687:\tlearn: 0.2231736\ttotal: 4m 36s\tremaining: 2m 5s\n",
            "688:\tlearn: 0.2230440\ttotal: 4m 37s\tremaining: 2m 5s\n",
            "689:\tlearn: 0.2229036\ttotal: 4m 37s\tremaining: 2m 4s\n",
            "690:\tlearn: 0.2226547\ttotal: 4m 37s\tremaining: 2m 4s\n",
            "691:\tlearn: 0.2224170\ttotal: 4m 38s\tremaining: 2m 3s\n",
            "692:\tlearn: 0.2221904\ttotal: 4m 39s\tremaining: 2m 3s\n",
            "693:\tlearn: 0.2220939\ttotal: 4m 39s\tremaining: 2m 3s\n",
            "694:\tlearn: 0.2219981\ttotal: 4m 40s\tremaining: 2m 3s\n",
            "695:\tlearn: 0.2217381\ttotal: 4m 40s\tremaining: 2m 2s\n",
            "696:\tlearn: 0.2215842\ttotal: 4m 41s\tremaining: 2m 2s\n",
            "697:\tlearn: 0.2214707\ttotal: 4m 41s\tremaining: 2m 1s\n",
            "698:\tlearn: 0.2211799\ttotal: 4m 41s\tremaining: 2m 1s\n",
            "699:\tlearn: 0.2210344\ttotal: 4m 42s\tremaining: 2m\n",
            "700:\tlearn: 0.2209008\ttotal: 4m 42s\tremaining: 2m\n",
            "701:\tlearn: 0.2206391\ttotal: 4m 43s\tremaining: 2m\n",
            "702:\tlearn: 0.2205057\ttotal: 4m 43s\tremaining: 1m 59s\n",
            "703:\tlearn: 0.2203953\ttotal: 4m 43s\tremaining: 1m 59s\n",
            "704:\tlearn: 0.2202968\ttotal: 4m 44s\tremaining: 1m 58s\n",
            "705:\tlearn: 0.2201881\ttotal: 4m 44s\tremaining: 1m 58s\n",
            "706:\tlearn: 0.2199338\ttotal: 4m 44s\tremaining: 1m 58s\n",
            "707:\tlearn: 0.2196970\ttotal: 4m 45s\tremaining: 1m 57s\n",
            "708:\tlearn: 0.2195490\ttotal: 4m 45s\tremaining: 1m 57s\n",
            "709:\tlearn: 0.2195012\ttotal: 4m 45s\tremaining: 1m 56s\n",
            "710:\tlearn: 0.2193073\ttotal: 4m 46s\tremaining: 1m 56s\n",
            "711:\tlearn: 0.2191960\ttotal: 4m 46s\tremaining: 1m 55s\n",
            "712:\tlearn: 0.2190645\ttotal: 4m 47s\tremaining: 1m 55s\n",
            "713:\tlearn: 0.2188090\ttotal: 4m 47s\tremaining: 1m 55s\n",
            "714:\tlearn: 0.2185374\ttotal: 4m 47s\tremaining: 1m 54s\n",
            "715:\tlearn: 0.2184416\ttotal: 4m 48s\tremaining: 1m 54s\n",
            "716:\tlearn: 0.2182166\ttotal: 4m 48s\tremaining: 1m 53s\n",
            "717:\tlearn: 0.2180438\ttotal: 4m 48s\tremaining: 1m 53s\n",
            "718:\tlearn: 0.2179249\ttotal: 4m 49s\tremaining: 1m 53s\n",
            "719:\tlearn: 0.2177611\ttotal: 4m 49s\tremaining: 1m 52s\n",
            "720:\tlearn: 0.2175665\ttotal: 4m 49s\tremaining: 1m 52s\n",
            "721:\tlearn: 0.2174469\ttotal: 4m 50s\tremaining: 1m 51s\n",
            "722:\tlearn: 0.2173287\ttotal: 4m 50s\tremaining: 1m 51s\n",
            "723:\tlearn: 0.2171023\ttotal: 4m 51s\tremaining: 1m 51s\n",
            "724:\tlearn: 0.2169422\ttotal: 4m 52s\tremaining: 1m 50s\n",
            "725:\tlearn: 0.2168614\ttotal: 4m 52s\tremaining: 1m 50s\n",
            "726:\tlearn: 0.2167891\ttotal: 4m 53s\tremaining: 1m 50s\n",
            "727:\tlearn: 0.2164737\ttotal: 4m 53s\tremaining: 1m 49s\n",
            "728:\tlearn: 0.2163263\ttotal: 4m 54s\tremaining: 1m 49s\n",
            "729:\tlearn: 0.2161638\ttotal: 4m 54s\tremaining: 1m 48s\n",
            "730:\tlearn: 0.2160705\ttotal: 4m 54s\tremaining: 1m 48s\n",
            "731:\tlearn: 0.2159566\ttotal: 4m 55s\tremaining: 1m 48s\n",
            "732:\tlearn: 0.2158343\ttotal: 4m 55s\tremaining: 1m 47s\n",
            "733:\tlearn: 0.2156577\ttotal: 4m 55s\tremaining: 1m 47s\n",
            "734:\tlearn: 0.2154829\ttotal: 4m 56s\tremaining: 1m 46s\n",
            "735:\tlearn: 0.2153656\ttotal: 4m 56s\tremaining: 1m 46s\n",
            "736:\tlearn: 0.2152401\ttotal: 4m 56s\tremaining: 1m 45s\n",
            "737:\tlearn: 0.2151365\ttotal: 4m 57s\tremaining: 1m 45s\n",
            "738:\tlearn: 0.2150628\ttotal: 4m 57s\tremaining: 1m 45s\n",
            "739:\tlearn: 0.2149051\ttotal: 4m 58s\tremaining: 1m 44s\n",
            "740:\tlearn: 0.2148155\ttotal: 4m 58s\tremaining: 1m 44s\n",
            "741:\tlearn: 0.2146382\ttotal: 4m 58s\tremaining: 1m 43s\n",
            "742:\tlearn: 0.2144536\ttotal: 4m 59s\tremaining: 1m 43s\n",
            "743:\tlearn: 0.2143578\ttotal: 4m 59s\tremaining: 1m 43s\n",
            "744:\tlearn: 0.2142295\ttotal: 4m 59s\tremaining: 1m 42s\n",
            "745:\tlearn: 0.2140302\ttotal: 5m\tremaining: 1m 42s\n",
            "746:\tlearn: 0.2139368\ttotal: 5m\tremaining: 1m 41s\n",
            "747:\tlearn: 0.2137771\ttotal: 5m\tremaining: 1m 41s\n",
            "748:\tlearn: 0.2136045\ttotal: 5m 1s\tremaining: 1m 40s\n",
            "749:\tlearn: 0.2134856\ttotal: 5m 1s\tremaining: 1m 40s\n",
            "750:\tlearn: 0.2132689\ttotal: 5m 2s\tremaining: 1m 40s\n",
            "751:\tlearn: 0.2130422\ttotal: 5m 2s\tremaining: 1m 39s\n",
            "752:\tlearn: 0.2129131\ttotal: 5m 2s\tremaining: 1m 39s\n",
            "753:\tlearn: 0.2126456\ttotal: 5m 3s\tremaining: 1m 38s\n",
            "754:\tlearn: 0.2124764\ttotal: 5m 3s\tremaining: 1m 38s\n",
            "755:\tlearn: 0.2122957\ttotal: 5m 4s\tremaining: 1m 38s\n",
            "756:\tlearn: 0.2122255\ttotal: 5m 5s\tremaining: 1m 37s\n",
            "757:\tlearn: 0.2120241\ttotal: 5m 5s\tremaining: 1m 37s\n",
            "758:\tlearn: 0.2117247\ttotal: 5m 6s\tremaining: 1m 37s\n",
            "759:\tlearn: 0.2115943\ttotal: 5m 6s\tremaining: 1m 36s\n",
            "760:\tlearn: 0.2114147\ttotal: 5m 6s\tremaining: 1m 36s\n",
            "761:\tlearn: 0.2112818\ttotal: 5m 7s\tremaining: 1m 35s\n",
            "762:\tlearn: 0.2111990\ttotal: 5m 7s\tremaining: 1m 35s\n",
            "763:\tlearn: 0.2111235\ttotal: 5m 7s\tremaining: 1m 35s\n",
            "764:\tlearn: 0.2109431\ttotal: 5m 8s\tremaining: 1m 34s\n",
            "765:\tlearn: 0.2107797\ttotal: 5m 8s\tremaining: 1m 34s\n",
            "766:\tlearn: 0.2106683\ttotal: 5m 9s\tremaining: 1m 33s\n",
            "767:\tlearn: 0.2104755\ttotal: 5m 9s\tremaining: 1m 33s\n",
            "768:\tlearn: 0.2103062\ttotal: 5m 9s\tremaining: 1m 33s\n",
            "769:\tlearn: 0.2101898\ttotal: 5m 10s\tremaining: 1m 32s\n",
            "770:\tlearn: 0.2100515\ttotal: 5m 10s\tremaining: 1m 32s\n",
            "771:\tlearn: 0.2099112\ttotal: 5m 10s\tremaining: 1m 31s\n",
            "772:\tlearn: 0.2097918\ttotal: 5m 11s\tremaining: 1m 31s\n",
            "773:\tlearn: 0.2096764\ttotal: 5m 11s\tremaining: 1m 30s\n",
            "774:\tlearn: 0.2093838\ttotal: 5m 11s\tremaining: 1m 30s\n",
            "775:\tlearn: 0.2092907\ttotal: 5m 12s\tremaining: 1m 30s\n",
            "776:\tlearn: 0.2091833\ttotal: 5m 12s\tremaining: 1m 29s\n",
            "777:\tlearn: 0.2090579\ttotal: 5m 13s\tremaining: 1m 29s\n",
            "778:\tlearn: 0.2088716\ttotal: 5m 13s\tremaining: 1m 28s\n",
            "779:\tlearn: 0.2088286\ttotal: 5m 13s\tremaining: 1m 28s\n",
            "780:\tlearn: 0.2087133\ttotal: 5m 14s\tremaining: 1m 28s\n",
            "781:\tlearn: 0.2086761\ttotal: 5m 14s\tremaining: 1m 27s\n",
            "782:\tlearn: 0.2085643\ttotal: 5m 14s\tremaining: 1m 27s\n",
            "783:\tlearn: 0.2084903\ttotal: 5m 15s\tremaining: 1m 26s\n",
            "784:\tlearn: 0.2084012\ttotal: 5m 15s\tremaining: 1m 26s\n",
            "785:\tlearn: 0.2083110\ttotal: 5m 16s\tremaining: 1m 26s\n",
            "786:\tlearn: 0.2082735\ttotal: 5m 16s\tremaining: 1m 25s\n",
            "787:\tlearn: 0.2081933\ttotal: 5m 17s\tremaining: 1m 25s\n",
            "788:\tlearn: 0.2080396\ttotal: 5m 18s\tremaining: 1m 25s\n",
            "789:\tlearn: 0.2079611\ttotal: 5m 18s\tremaining: 1m 24s\n",
            "790:\tlearn: 0.2078660\ttotal: 5m 18s\tremaining: 1m 24s\n",
            "791:\tlearn: 0.2077691\ttotal: 5m 19s\tremaining: 1m 23s\n",
            "792:\tlearn: 0.2076095\ttotal: 5m 19s\tremaining: 1m 23s\n",
            "793:\tlearn: 0.2075274\ttotal: 5m 19s\tremaining: 1m 23s\n",
            "794:\tlearn: 0.2073083\ttotal: 5m 20s\tremaining: 1m 22s\n",
            "795:\tlearn: 0.2070939\ttotal: 5m 20s\tremaining: 1m 22s\n",
            "796:\tlearn: 0.2070411\ttotal: 5m 21s\tremaining: 1m 21s\n",
            "797:\tlearn: 0.2069013\ttotal: 5m 21s\tremaining: 1m 21s\n",
            "798:\tlearn: 0.2067477\ttotal: 5m 21s\tremaining: 1m 20s\n",
            "799:\tlearn: 0.2066453\ttotal: 5m 22s\tremaining: 1m 20s\n",
            "800:\tlearn: 0.2065454\ttotal: 5m 22s\tremaining: 1m 20s\n",
            "801:\tlearn: 0.2064619\ttotal: 5m 22s\tremaining: 1m 19s\n",
            "802:\tlearn: 0.2063665\ttotal: 5m 23s\tremaining: 1m 19s\n",
            "803:\tlearn: 0.2061217\ttotal: 5m 23s\tremaining: 1m 18s\n",
            "804:\tlearn: 0.2060281\ttotal: 5m 23s\tremaining: 1m 18s\n",
            "805:\tlearn: 0.2059568\ttotal: 5m 24s\tremaining: 1m 18s\n",
            "806:\tlearn: 0.2057767\ttotal: 5m 24s\tremaining: 1m 17s\n",
            "807:\tlearn: 0.2056802\ttotal: 5m 25s\tremaining: 1m 17s\n",
            "808:\tlearn: 0.2055666\ttotal: 5m 25s\tremaining: 1m 16s\n",
            "809:\tlearn: 0.2053936\ttotal: 5m 25s\tremaining: 1m 16s\n",
            "810:\tlearn: 0.2052994\ttotal: 5m 26s\tremaining: 1m 16s\n",
            "811:\tlearn: 0.2050792\ttotal: 5m 26s\tremaining: 1m 15s\n",
            "812:\tlearn: 0.2049900\ttotal: 5m 26s\tremaining: 1m 15s\n",
            "813:\tlearn: 0.2048748\ttotal: 5m 27s\tremaining: 1m 14s\n",
            "814:\tlearn: 0.2047710\ttotal: 5m 27s\tremaining: 1m 14s\n",
            "815:\tlearn: 0.2046049\ttotal: 5m 27s\tremaining: 1m 13s\n",
            "816:\tlearn: 0.2045266\ttotal: 5m 28s\tremaining: 1m 13s\n",
            "817:\tlearn: 0.2044315\ttotal: 5m 28s\tremaining: 1m 13s\n",
            "818:\tlearn: 0.2043179\ttotal: 5m 29s\tremaining: 1m 12s\n",
            "819:\tlearn: 0.2041283\ttotal: 5m 30s\tremaining: 1m 12s\n",
            "820:\tlearn: 0.2039791\ttotal: 5m 30s\tremaining: 1m 12s\n",
            "821:\tlearn: 0.2038010\ttotal: 5m 31s\tremaining: 1m 11s\n",
            "822:\tlearn: 0.2035263\ttotal: 5m 31s\tremaining: 1m 11s\n",
            "823:\tlearn: 0.2031788\ttotal: 5m 31s\tremaining: 1m 10s\n",
            "824:\tlearn: 0.2031049\ttotal: 5m 32s\tremaining: 1m 10s\n",
            "825:\tlearn: 0.2028769\ttotal: 5m 32s\tremaining: 1m 10s\n",
            "826:\tlearn: 0.2026965\ttotal: 5m 33s\tremaining: 1m 9s\n",
            "827:\tlearn: 0.2025087\ttotal: 5m 33s\tremaining: 1m 9s\n",
            "828:\tlearn: 0.2022994\ttotal: 5m 33s\tremaining: 1m 8s\n",
            "829:\tlearn: 0.2022404\ttotal: 5m 34s\tremaining: 1m 8s\n",
            "830:\tlearn: 0.2021994\ttotal: 5m 34s\tremaining: 1m 8s\n",
            "831:\tlearn: 0.2020136\ttotal: 5m 34s\tremaining: 1m 7s\n",
            "832:\tlearn: 0.2017539\ttotal: 5m 35s\tremaining: 1m 7s\n",
            "833:\tlearn: 0.2015382\ttotal: 5m 35s\tremaining: 1m 6s\n",
            "834:\tlearn: 0.2013476\ttotal: 5m 36s\tremaining: 1m 6s\n",
            "835:\tlearn: 0.2012276\ttotal: 5m 36s\tremaining: 1m 5s\n",
            "836:\tlearn: 0.2011563\ttotal: 5m 36s\tremaining: 1m 5s\n",
            "837:\tlearn: 0.2010224\ttotal: 5m 37s\tremaining: 1m 5s\n",
            "838:\tlearn: 0.2008691\ttotal: 5m 37s\tremaining: 1m 4s\n",
            "839:\tlearn: 0.2006582\ttotal: 5m 37s\tremaining: 1m 4s\n",
            "840:\tlearn: 0.2005212\ttotal: 5m 38s\tremaining: 1m 3s\n",
            "841:\tlearn: 0.2003471\ttotal: 5m 38s\tremaining: 1m 3s\n",
            "842:\tlearn: 0.2002691\ttotal: 5m 38s\tremaining: 1m 3s\n",
            "843:\tlearn: 0.2001231\ttotal: 5m 39s\tremaining: 1m 2s\n",
            "844:\tlearn: 0.2000716\ttotal: 5m 39s\tremaining: 1m 2s\n",
            "845:\tlearn: 0.1999624\ttotal: 5m 40s\tremaining: 1m 1s\n",
            "846:\tlearn: 0.1998996\ttotal: 5m 40s\tremaining: 1m 1s\n",
            "847:\tlearn: 0.1997681\ttotal: 5m 40s\tremaining: 1m 1s\n",
            "848:\tlearn: 0.1996442\ttotal: 5m 41s\tremaining: 1m\n",
            "849:\tlearn: 0.1995837\ttotal: 5m 41s\tremaining: 1m\n",
            "850:\tlearn: 0.1995041\ttotal: 5m 42s\tremaining: 60s\n",
            "851:\tlearn: 0.1993318\ttotal: 5m 43s\tremaining: 59.6s\n",
            "852:\tlearn: 0.1992410\ttotal: 5m 43s\tremaining: 59.2s\n",
            "853:\tlearn: 0.1991853\ttotal: 5m 44s\tremaining: 58.8s\n",
            "854:\tlearn: 0.1990482\ttotal: 5m 44s\tremaining: 58.4s\n",
            "855:\tlearn: 0.1989214\ttotal: 5m 44s\tremaining: 58s\n",
            "856:\tlearn: 0.1987462\ttotal: 5m 45s\tremaining: 57.6s\n",
            "857:\tlearn: 0.1986523\ttotal: 5m 45s\tremaining: 57.2s\n",
            "858:\tlearn: 0.1985990\ttotal: 5m 45s\tremaining: 56.8s\n",
            "859:\tlearn: 0.1984312\ttotal: 5m 46s\tremaining: 56.4s\n",
            "860:\tlearn: 0.1982432\ttotal: 5m 46s\tremaining: 56s\n",
            "861:\tlearn: 0.1981139\ttotal: 5m 46s\tremaining: 55.6s\n",
            "862:\tlearn: 0.1980113\ttotal: 5m 47s\tremaining: 55.1s\n",
            "863:\tlearn: 0.1979046\ttotal: 5m 47s\tremaining: 54.7s\n",
            "864:\tlearn: 0.1976922\ttotal: 5m 48s\tremaining: 54.3s\n",
            "865:\tlearn: 0.1976281\ttotal: 5m 48s\tremaining: 53.9s\n",
            "866:\tlearn: 0.1974946\ttotal: 5m 48s\tremaining: 53.5s\n",
            "867:\tlearn: 0.1973998\ttotal: 5m 49s\tremaining: 53.1s\n",
            "868:\tlearn: 0.1973480\ttotal: 5m 49s\tremaining: 52.7s\n",
            "869:\tlearn: 0.1972054\ttotal: 5m 49s\tremaining: 52.3s\n",
            "870:\tlearn: 0.1971673\ttotal: 5m 50s\tremaining: 51.9s\n",
            "871:\tlearn: 0.1969846\ttotal: 5m 50s\tremaining: 51.5s\n",
            "872:\tlearn: 0.1969119\ttotal: 5m 51s\tremaining: 51.1s\n",
            "873:\tlearn: 0.1968009\ttotal: 5m 51s\tremaining: 50.7s\n",
            "874:\tlearn: 0.1966664\ttotal: 5m 51s\tremaining: 50.2s\n",
            "875:\tlearn: 0.1966182\ttotal: 5m 52s\tremaining: 49.8s\n",
            "876:\tlearn: 0.1965526\ttotal: 5m 52s\tremaining: 49.4s\n",
            "877:\tlearn: 0.1964789\ttotal: 5m 52s\tremaining: 49s\n",
            "878:\tlearn: 0.1963728\ttotal: 5m 53s\tremaining: 48.6s\n",
            "879:\tlearn: 0.1962912\ttotal: 5m 53s\tremaining: 48.2s\n",
            "880:\tlearn: 0.1962428\ttotal: 5m 54s\tremaining: 47.8s\n",
            "881:\tlearn: 0.1961134\ttotal: 5m 54s\tremaining: 47.5s\n",
            "882:\tlearn: 0.1960254\ttotal: 5m 55s\tremaining: 47.1s\n",
            "883:\tlearn: 0.1959618\ttotal: 5m 56s\tremaining: 46.7s\n",
            "884:\tlearn: 0.1958499\ttotal: 5m 56s\tremaining: 46.3s\n",
            "885:\tlearn: 0.1955846\ttotal: 5m 56s\tremaining: 45.9s\n",
            "886:\tlearn: 0.1955319\ttotal: 5m 57s\tremaining: 45.5s\n",
            "887:\tlearn: 0.1954659\ttotal: 5m 57s\tremaining: 45.1s\n",
            "888:\tlearn: 0.1953217\ttotal: 5m 57s\tremaining: 44.7s\n",
            "889:\tlearn: 0.1952396\ttotal: 5m 58s\tremaining: 44.3s\n",
            "890:\tlearn: 0.1951267\ttotal: 5m 58s\tremaining: 43.9s\n",
            "891:\tlearn: 0.1950483\ttotal: 5m 59s\tremaining: 43.5s\n",
            "892:\tlearn: 0.1949849\ttotal: 5m 59s\tremaining: 43.1s\n",
            "893:\tlearn: 0.1949175\ttotal: 5m 59s\tremaining: 42.7s\n",
            "894:\tlearn: 0.1948404\ttotal: 6m\tremaining: 42.2s\n",
            "895:\tlearn: 0.1946730\ttotal: 6m\tremaining: 41.8s\n",
            "896:\tlearn: 0.1946149\ttotal: 6m\tremaining: 41.4s\n",
            "897:\tlearn: 0.1944899\ttotal: 6m 1s\tremaining: 41s\n",
            "898:\tlearn: 0.1942666\ttotal: 6m 1s\tremaining: 40.6s\n",
            "899:\tlearn: 0.1941053\ttotal: 6m 1s\tremaining: 40.2s\n",
            "900:\tlearn: 0.1940528\ttotal: 6m 2s\tremaining: 39.8s\n",
            "901:\tlearn: 0.1938870\ttotal: 6m 2s\tremaining: 39.4s\n",
            "902:\tlearn: 0.1937156\ttotal: 6m 3s\tremaining: 39s\n",
            "903:\tlearn: 0.1935295\ttotal: 6m 3s\tremaining: 38.6s\n",
            "904:\tlearn: 0.1934113\ttotal: 6m 3s\tremaining: 38.2s\n",
            "905:\tlearn: 0.1933534\ttotal: 6m 4s\tremaining: 37.8s\n",
            "906:\tlearn: 0.1932257\ttotal: 6m 4s\tremaining: 37.4s\n",
            "907:\tlearn: 0.1930067\ttotal: 6m 4s\tremaining: 37s\n",
            "908:\tlearn: 0.1929560\ttotal: 6m 5s\tremaining: 36.6s\n",
            "909:\tlearn: 0.1929010\ttotal: 6m 5s\tremaining: 36.2s\n",
            "910:\tlearn: 0.1927076\ttotal: 6m 5s\tremaining: 35.8s\n",
            "911:\tlearn: 0.1925806\ttotal: 6m 6s\tremaining: 35.4s\n",
            "912:\tlearn: 0.1924127\ttotal: 6m 7s\tremaining: 35s\n",
            "913:\tlearn: 0.1922060\ttotal: 6m 7s\tremaining: 34.6s\n",
            "914:\tlearn: 0.1919404\ttotal: 6m 8s\tremaining: 34.2s\n",
            "915:\tlearn: 0.1918300\ttotal: 6m 8s\tremaining: 33.8s\n",
            "916:\tlearn: 0.1917313\ttotal: 6m 9s\tremaining: 33.4s\n",
            "917:\tlearn: 0.1915903\ttotal: 6m 9s\tremaining: 33s\n",
            "918:\tlearn: 0.1914832\ttotal: 6m 9s\tremaining: 32.6s\n",
            "919:\tlearn: 0.1914188\ttotal: 6m 10s\tremaining: 32.2s\n",
            "920:\tlearn: 0.1913026\ttotal: 6m 10s\tremaining: 31.8s\n",
            "921:\tlearn: 0.1911506\ttotal: 6m 10s\tremaining: 31.4s\n",
            "922:\tlearn: 0.1909777\ttotal: 6m 11s\tremaining: 31s\n",
            "923:\tlearn: 0.1908889\ttotal: 6m 11s\tremaining: 30.6s\n",
            "924:\tlearn: 0.1907412\ttotal: 6m 12s\tremaining: 30.2s\n",
            "925:\tlearn: 0.1906774\ttotal: 6m 12s\tremaining: 29.8s\n",
            "926:\tlearn: 0.1905979\ttotal: 6m 12s\tremaining: 29.4s\n",
            "927:\tlearn: 0.1904596\ttotal: 6m 13s\tremaining: 29s\n",
            "928:\tlearn: 0.1903127\ttotal: 6m 13s\tremaining: 28.6s\n",
            "929:\tlearn: 0.1901814\ttotal: 6m 13s\tremaining: 28.1s\n",
            "930:\tlearn: 0.1900469\ttotal: 6m 14s\tremaining: 27.7s\n",
            "931:\tlearn: 0.1899604\ttotal: 6m 14s\tremaining: 27.3s\n",
            "932:\tlearn: 0.1898689\ttotal: 6m 15s\tremaining: 26.9s\n",
            "933:\tlearn: 0.1897449\ttotal: 6m 15s\tremaining: 26.5s\n",
            "934:\tlearn: 0.1896607\ttotal: 6m 15s\tremaining: 26.1s\n",
            "935:\tlearn: 0.1894833\ttotal: 6m 16s\tremaining: 25.7s\n",
            "936:\tlearn: 0.1893375\ttotal: 6m 16s\tremaining: 25.3s\n",
            "937:\tlearn: 0.1892447\ttotal: 6m 16s\tremaining: 24.9s\n",
            "938:\tlearn: 0.1890474\ttotal: 6m 17s\tremaining: 24.5s\n",
            "939:\tlearn: 0.1889457\ttotal: 6m 17s\tremaining: 24.1s\n",
            "940:\tlearn: 0.1887675\ttotal: 6m 17s\tremaining: 23.7s\n",
            "941:\tlearn: 0.1886696\ttotal: 6m 18s\tremaining: 23.3s\n",
            "942:\tlearn: 0.1885485\ttotal: 6m 18s\tremaining: 22.9s\n",
            "943:\tlearn: 0.1884404\ttotal: 6m 19s\tremaining: 22.5s\n",
            "944:\tlearn: 0.1883754\ttotal: 6m 19s\tremaining: 22.1s\n",
            "945:\tlearn: 0.1882584\ttotal: 6m 20s\tremaining: 21.7s\n",
            "946:\tlearn: 0.1881694\ttotal: 6m 21s\tremaining: 21.3s\n",
            "947:\tlearn: 0.1880990\ttotal: 6m 21s\tremaining: 20.9s\n",
            "948:\tlearn: 0.1879575\ttotal: 6m 21s\tremaining: 20.5s\n",
            "949:\tlearn: 0.1877995\ttotal: 6m 22s\tremaining: 20.1s\n",
            "950:\tlearn: 0.1877265\ttotal: 6m 22s\tremaining: 19.7s\n",
            "951:\tlearn: 0.1876049\ttotal: 6m 23s\tremaining: 19.3s\n",
            "952:\tlearn: 0.1874547\ttotal: 6m 23s\tremaining: 18.9s\n",
            "953:\tlearn: 0.1873847\ttotal: 6m 23s\tremaining: 18.5s\n",
            "954:\tlearn: 0.1872149\ttotal: 6m 24s\tremaining: 18.1s\n",
            "955:\tlearn: 0.1870048\ttotal: 6m 24s\tremaining: 17.7s\n",
            "956:\tlearn: 0.1868912\ttotal: 6m 24s\tremaining: 17.3s\n",
            "957:\tlearn: 0.1868264\ttotal: 6m 25s\tremaining: 16.9s\n",
            "958:\tlearn: 0.1867458\ttotal: 6m 25s\tremaining: 16.5s\n",
            "959:\tlearn: 0.1865329\ttotal: 6m 25s\tremaining: 16.1s\n",
            "960:\tlearn: 0.1863293\ttotal: 6m 26s\tremaining: 15.7s\n",
            "961:\tlearn: 0.1862530\ttotal: 6m 26s\tremaining: 15.3s\n",
            "962:\tlearn: 0.1861393\ttotal: 6m 27s\tremaining: 14.9s\n",
            "963:\tlearn: 0.1859736\ttotal: 6m 27s\tremaining: 14.5s\n",
            "964:\tlearn: 0.1857926\ttotal: 6m 27s\tremaining: 14.1s\n",
            "965:\tlearn: 0.1856661\ttotal: 6m 28s\tremaining: 13.7s\n",
            "966:\tlearn: 0.1855234\ttotal: 6m 28s\tremaining: 13.3s\n",
            "967:\tlearn: 0.1854716\ttotal: 6m 28s\tremaining: 12.9s\n",
            "968:\tlearn: 0.1853482\ttotal: 6m 29s\tremaining: 12.4s\n",
            "969:\tlearn: 0.1852288\ttotal: 6m 29s\tremaining: 12s\n",
            "970:\tlearn: 0.1849514\ttotal: 6m 29s\tremaining: 11.6s\n",
            "971:\tlearn: 0.1847506\ttotal: 6m 30s\tremaining: 11.2s\n",
            "972:\tlearn: 0.1845848\ttotal: 6m 30s\tremaining: 10.8s\n",
            "973:\tlearn: 0.1844036\ttotal: 6m 31s\tremaining: 10.4s\n",
            "974:\tlearn: 0.1843131\ttotal: 6m 31s\tremaining: 10s\n",
            "975:\tlearn: 0.1842285\ttotal: 6m 32s\tremaining: 9.64s\n",
            "976:\tlearn: 0.1841388\ttotal: 6m 32s\tremaining: 9.24s\n",
            "977:\tlearn: 0.1840374\ttotal: 6m 33s\tremaining: 8.85s\n",
            "978:\tlearn: 0.1839213\ttotal: 6m 33s\tremaining: 8.45s\n",
            "979:\tlearn: 0.1838688\ttotal: 6m 34s\tremaining: 8.04s\n",
            "980:\tlearn: 0.1837530\ttotal: 6m 34s\tremaining: 7.64s\n",
            "981:\tlearn: 0.1836186\ttotal: 6m 34s\tremaining: 7.24s\n",
            "982:\tlearn: 0.1834960\ttotal: 6m 35s\tremaining: 6.84s\n",
            "983:\tlearn: 0.1833459\ttotal: 6m 35s\tremaining: 6.43s\n",
            "984:\tlearn: 0.1831528\ttotal: 6m 36s\tremaining: 6.03s\n",
            "985:\tlearn: 0.1829312\ttotal: 6m 36s\tremaining: 5.63s\n",
            "986:\tlearn: 0.1827679\ttotal: 6m 36s\tremaining: 5.23s\n",
            "987:\tlearn: 0.1826610\ttotal: 6m 37s\tremaining: 4.82s\n",
            "988:\tlearn: 0.1825484\ttotal: 6m 37s\tremaining: 4.42s\n",
            "989:\tlearn: 0.1823372\ttotal: 6m 37s\tremaining: 4.02s\n",
            "990:\tlearn: 0.1821841\ttotal: 6m 38s\tremaining: 3.62s\n",
            "991:\tlearn: 0.1820534\ttotal: 6m 38s\tremaining: 3.21s\n",
            "992:\tlearn: 0.1819236\ttotal: 6m 39s\tremaining: 2.81s\n",
            "993:\tlearn: 0.1818626\ttotal: 6m 39s\tremaining: 2.41s\n",
            "994:\tlearn: 0.1817747\ttotal: 6m 39s\tremaining: 2.01s\n",
            "995:\tlearn: 0.1816870\ttotal: 6m 40s\tremaining: 1.61s\n",
            "996:\tlearn: 0.1816013\ttotal: 6m 40s\tremaining: 1.21s\n",
            "997:\tlearn: 0.1815168\ttotal: 6m 40s\tremaining: 803ms\n",
            "998:\tlearn: 0.1813062\ttotal: 6m 41s\tremaining: 402ms\n",
            "999:\tlearn: 0.1811840\ttotal: 6m 41s\tremaining: 0us\n",
            "0.8757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_all, model.predict(X_pca)))"
      ],
      "metadata": {
        "id": "4XbXp0K8MV6l",
        "outputId": "bbbe7813-e761-4a40-c80f-8151073c1dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCBFxcRjemw6"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "mOahRRQMemw6",
        "outputId": "33627f1a-2837-4b89-f601-dbf0926bc69b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.94357\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_3 = get_accuracy(model_task_3, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SDorq3eeemw6",
        "outputId": "df27ce4a-e93d-4069-d5c3-b41ce79ea2be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.8985\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_3 = get_accuracy(model_task_3, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_3:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVuJiuzFemw6"
      },
      "source": [
        "Проверка, что переобучение присутствует:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tlb9xHd2emw6",
        "outputId": "3d936db6-4f43-4b7e-fe67-506d35a85b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Test accuracy should not be lower that train more than by 0.015",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2017449451>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.865\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Test accuracy must be higher than 0.865\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m assert (\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_acc_task_3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_acc_task_3\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.015\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m ), \"Test accuracy should not be lower that train more than by 0.015\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Test accuracy should not be lower that train more than by 0.015"
          ]
        }
      ],
      "source": [
        "assert train_acc_task_3 >= 0.88, \"Train accuracy must be higher than 0.88\"\n",
        "assert train_acc_task_3 >= 0.865, \"Test accuracy must be higher than 0.865\"\n",
        "assert (\n",
        "    train_acc_task_3 - test_acc_task_3 <= 0.015\n",
        "), \"Test accuracy should not be lower that train more than by 0.015\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ARVFNGNemw6"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_3`.\n",
        "\n",
        "Также предполагается, что в переменной `submission_dict` уже содержатся результаты задач №1 и №2. Если их там нет, загрузите их из сохраненных файлов перед запуском следующей ячейки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dov0JB_Jemw6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_overfitting_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict.update(\n",
        "    {\n",
        "        \"train_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "        ),\n",
        "        \"test_predictions_task_3\": get_predictions(\n",
        "            model_task_3, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "        ),\n",
        "        \"model_task_3\": parse_pytorch_model(str(model_task_3)),\n",
        "    }\n",
        ")\n",
        "\n",
        "with open(\"submission_dict_final.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_final.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированные файлы в соответствующие задачи в соревновании, а именно:\n",
        "* `submission_dict_tasks_1_and_2.json` в задачу Initiation\n",
        "* `submission_dict_final.json` в задачу Return.\n",
        "\n",
        "\n",
        "`submission_dict_task_1.json` сдавать не нужно, он уже был сдан ранее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}